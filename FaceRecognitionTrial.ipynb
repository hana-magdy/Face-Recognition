{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FaceRecognition.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hana-magdy/Face-Recognition/blob/main/FaceRecognitionTrial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oIpQQwnlhUkX"
      },
      "source": [
        "Imports:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d4djDiQnhXqk"
      },
      "source": [
        "from PIL import Image\n",
        "from numpy import asarray\n",
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np\n",
        "import glob\n",
        "import cv2\n",
        "import zipfile\n",
        "import  os\n",
        "from scipy.spatial import distance\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from tabulate import tabulate\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qOfuTWnFhnWA"
      },
      "source": [
        "zip_ref = zipfile.ZipFile(\"archive (1).zip\", \"r\")\n",
        "zip_ref.extractall()\n",
        "zip_ref.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DO8Zy3iwh2HU",
        "outputId": "02e907f4-8ac6-479c-9d71-3255c503300c"
      },
      "source": [
        " \n",
        "y = []\n",
        "Data_matrix = []\n",
        "for i in range(1,41):\n",
        "  folder = \"s\"\n",
        "  folder+=str(i)\n",
        "  y.append(i)\n",
        "  files = glob.glob (folder)\n",
        "  for j in range(1,11):\n",
        "      file_name = folder + \"/\"+str(j)+\".pgm\"\n",
        "      img = Image.open(file_name)\n",
        "      data = np.array(img)\n",
        "      #print(data)\n",
        "      x = data.flatten()\n",
        "      Data_matrix.append(x)\n",
        "      #print(x.shape)\n",
        "      print(\"Path\")\n",
        "      print(file_name)\n",
        "      j=j+1\n",
        "  j = 1\n",
        "  i = i +1"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Path\n",
            "s1/1.pgm\n",
            "Path\n",
            "s1/2.pgm\n",
            "Path\n",
            "s1/3.pgm\n",
            "Path\n",
            "s1/4.pgm\n",
            "Path\n",
            "s1/5.pgm\n",
            "Path\n",
            "s1/6.pgm\n",
            "Path\n",
            "s1/7.pgm\n",
            "Path\n",
            "s1/8.pgm\n",
            "Path\n",
            "s1/9.pgm\n",
            "Path\n",
            "s1/10.pgm\n",
            "Path\n",
            "s2/1.pgm\n",
            "Path\n",
            "s2/2.pgm\n",
            "Path\n",
            "s2/3.pgm\n",
            "Path\n",
            "s2/4.pgm\n",
            "Path\n",
            "s2/5.pgm\n",
            "Path\n",
            "s2/6.pgm\n",
            "Path\n",
            "s2/7.pgm\n",
            "Path\n",
            "s2/8.pgm\n",
            "Path\n",
            "s2/9.pgm\n",
            "Path\n",
            "s2/10.pgm\n",
            "Path\n",
            "s3/1.pgm\n",
            "Path\n",
            "s3/2.pgm\n",
            "Path\n",
            "s3/3.pgm\n",
            "Path\n",
            "s3/4.pgm\n",
            "Path\n",
            "s3/5.pgm\n",
            "Path\n",
            "s3/6.pgm\n",
            "Path\n",
            "s3/7.pgm\n",
            "Path\n",
            "s3/8.pgm\n",
            "Path\n",
            "s3/9.pgm\n",
            "Path\n",
            "s3/10.pgm\n",
            "Path\n",
            "s4/1.pgm\n",
            "Path\n",
            "s4/2.pgm\n",
            "Path\n",
            "s4/3.pgm\n",
            "Path\n",
            "s4/4.pgm\n",
            "Path\n",
            "s4/5.pgm\n",
            "Path\n",
            "s4/6.pgm\n",
            "Path\n",
            "s4/7.pgm\n",
            "Path\n",
            "s4/8.pgm\n",
            "Path\n",
            "s4/9.pgm\n",
            "Path\n",
            "s4/10.pgm\n",
            "Path\n",
            "s5/1.pgm\n",
            "Path\n",
            "s5/2.pgm\n",
            "Path\n",
            "s5/3.pgm\n",
            "Path\n",
            "s5/4.pgm\n",
            "Path\n",
            "s5/5.pgm\n",
            "Path\n",
            "s5/6.pgm\n",
            "Path\n",
            "s5/7.pgm\n",
            "Path\n",
            "s5/8.pgm\n",
            "Path\n",
            "s5/9.pgm\n",
            "Path\n",
            "s5/10.pgm\n",
            "Path\n",
            "s6/1.pgm\n",
            "Path\n",
            "s6/2.pgm\n",
            "Path\n",
            "s6/3.pgm\n",
            "Path\n",
            "s6/4.pgm\n",
            "Path\n",
            "s6/5.pgm\n",
            "Path\n",
            "s6/6.pgm\n",
            "Path\n",
            "s6/7.pgm\n",
            "Path\n",
            "s6/8.pgm\n",
            "Path\n",
            "s6/9.pgm\n",
            "Path\n",
            "s6/10.pgm\n",
            "Path\n",
            "s7/1.pgm\n",
            "Path\n",
            "s7/2.pgm\n",
            "Path\n",
            "s7/3.pgm\n",
            "Path\n",
            "s7/4.pgm\n",
            "Path\n",
            "s7/5.pgm\n",
            "Path\n",
            "s7/6.pgm\n",
            "Path\n",
            "s7/7.pgm\n",
            "Path\n",
            "s7/8.pgm\n",
            "Path\n",
            "s7/9.pgm\n",
            "Path\n",
            "s7/10.pgm\n",
            "Path\n",
            "s8/1.pgm\n",
            "Path\n",
            "s8/2.pgm\n",
            "Path\n",
            "s8/3.pgm\n",
            "Path\n",
            "s8/4.pgm\n",
            "Path\n",
            "s8/5.pgm\n",
            "Path\n",
            "s8/6.pgm\n",
            "Path\n",
            "s8/7.pgm\n",
            "Path\n",
            "s8/8.pgm\n",
            "Path\n",
            "s8/9.pgm\n",
            "Path\n",
            "s8/10.pgm\n",
            "Path\n",
            "s9/1.pgm\n",
            "Path\n",
            "s9/2.pgm\n",
            "Path\n",
            "s9/3.pgm\n",
            "Path\n",
            "s9/4.pgm\n",
            "Path\n",
            "s9/5.pgm\n",
            "Path\n",
            "s9/6.pgm\n",
            "Path\n",
            "s9/7.pgm\n",
            "Path\n",
            "s9/8.pgm\n",
            "Path\n",
            "s9/9.pgm\n",
            "Path\n",
            "s9/10.pgm\n",
            "Path\n",
            "s10/1.pgm\n",
            "Path\n",
            "s10/2.pgm\n",
            "Path\n",
            "s10/3.pgm\n",
            "Path\n",
            "s10/4.pgm\n",
            "Path\n",
            "s10/5.pgm\n",
            "Path\n",
            "s10/6.pgm\n",
            "Path\n",
            "s10/7.pgm\n",
            "Path\n",
            "s10/8.pgm\n",
            "Path\n",
            "s10/9.pgm\n",
            "Path\n",
            "s10/10.pgm\n",
            "Path\n",
            "s11/1.pgm\n",
            "Path\n",
            "s11/2.pgm\n",
            "Path\n",
            "s11/3.pgm\n",
            "Path\n",
            "s11/4.pgm\n",
            "Path\n",
            "s11/5.pgm\n",
            "Path\n",
            "s11/6.pgm\n",
            "Path\n",
            "s11/7.pgm\n",
            "Path\n",
            "s11/8.pgm\n",
            "Path\n",
            "s11/9.pgm\n",
            "Path\n",
            "s11/10.pgm\n",
            "Path\n",
            "s12/1.pgm\n",
            "Path\n",
            "s12/2.pgm\n",
            "Path\n",
            "s12/3.pgm\n",
            "Path\n",
            "s12/4.pgm\n",
            "Path\n",
            "s12/5.pgm\n",
            "Path\n",
            "s12/6.pgm\n",
            "Path\n",
            "s12/7.pgm\n",
            "Path\n",
            "s12/8.pgm\n",
            "Path\n",
            "s12/9.pgm\n",
            "Path\n",
            "s12/10.pgm\n",
            "Path\n",
            "s13/1.pgm\n",
            "Path\n",
            "s13/2.pgm\n",
            "Path\n",
            "s13/3.pgm\n",
            "Path\n",
            "s13/4.pgm\n",
            "Path\n",
            "s13/5.pgm\n",
            "Path\n",
            "s13/6.pgm\n",
            "Path\n",
            "s13/7.pgm\n",
            "Path\n",
            "s13/8.pgm\n",
            "Path\n",
            "s13/9.pgm\n",
            "Path\n",
            "s13/10.pgm\n",
            "Path\n",
            "s14/1.pgm\n",
            "Path\n",
            "s14/2.pgm\n",
            "Path\n",
            "s14/3.pgm\n",
            "Path\n",
            "s14/4.pgm\n",
            "Path\n",
            "s14/5.pgm\n",
            "Path\n",
            "s14/6.pgm\n",
            "Path\n",
            "s14/7.pgm\n",
            "Path\n",
            "s14/8.pgm\n",
            "Path\n",
            "s14/9.pgm\n",
            "Path\n",
            "s14/10.pgm\n",
            "Path\n",
            "s15/1.pgm\n",
            "Path\n",
            "s15/2.pgm\n",
            "Path\n",
            "s15/3.pgm\n",
            "Path\n",
            "s15/4.pgm\n",
            "Path\n",
            "s15/5.pgm\n",
            "Path\n",
            "s15/6.pgm\n",
            "Path\n",
            "s15/7.pgm\n",
            "Path\n",
            "s15/8.pgm\n",
            "Path\n",
            "s15/9.pgm\n",
            "Path\n",
            "s15/10.pgm\n",
            "Path\n",
            "s16/1.pgm\n",
            "Path\n",
            "s16/2.pgm\n",
            "Path\n",
            "s16/3.pgm\n",
            "Path\n",
            "s16/4.pgm\n",
            "Path\n",
            "s16/5.pgm\n",
            "Path\n",
            "s16/6.pgm\n",
            "Path\n",
            "s16/7.pgm\n",
            "Path\n",
            "s16/8.pgm\n",
            "Path\n",
            "s16/9.pgm\n",
            "Path\n",
            "s16/10.pgm\n",
            "Path\n",
            "s17/1.pgm\n",
            "Path\n",
            "s17/2.pgm\n",
            "Path\n",
            "s17/3.pgm\n",
            "Path\n",
            "s17/4.pgm\n",
            "Path\n",
            "s17/5.pgm\n",
            "Path\n",
            "s17/6.pgm\n",
            "Path\n",
            "s17/7.pgm\n",
            "Path\n",
            "s17/8.pgm\n",
            "Path\n",
            "s17/9.pgm\n",
            "Path\n",
            "s17/10.pgm\n",
            "Path\n",
            "s18/1.pgm\n",
            "Path\n",
            "s18/2.pgm\n",
            "Path\n",
            "s18/3.pgm\n",
            "Path\n",
            "s18/4.pgm\n",
            "Path\n",
            "s18/5.pgm\n",
            "Path\n",
            "s18/6.pgm\n",
            "Path\n",
            "s18/7.pgm\n",
            "Path\n",
            "s18/8.pgm\n",
            "Path\n",
            "s18/9.pgm\n",
            "Path\n",
            "s18/10.pgm\n",
            "Path\n",
            "s19/1.pgm\n",
            "Path\n",
            "s19/2.pgm\n",
            "Path\n",
            "s19/3.pgm\n",
            "Path\n",
            "s19/4.pgm\n",
            "Path\n",
            "s19/5.pgm\n",
            "Path\n",
            "s19/6.pgm\n",
            "Path\n",
            "s19/7.pgm\n",
            "Path\n",
            "s19/8.pgm\n",
            "Path\n",
            "s19/9.pgm\n",
            "Path\n",
            "s19/10.pgm\n",
            "Path\n",
            "s20/1.pgm\n",
            "Path\n",
            "s20/2.pgm\n",
            "Path\n",
            "s20/3.pgm\n",
            "Path\n",
            "s20/4.pgm\n",
            "Path\n",
            "s20/5.pgm\n",
            "Path\n",
            "s20/6.pgm\n",
            "Path\n",
            "s20/7.pgm\n",
            "Path\n",
            "s20/8.pgm\n",
            "Path\n",
            "s20/9.pgm\n",
            "Path\n",
            "s20/10.pgm\n",
            "Path\n",
            "s21/1.pgm\n",
            "Path\n",
            "s21/2.pgm\n",
            "Path\n",
            "s21/3.pgm\n",
            "Path\n",
            "s21/4.pgm\n",
            "Path\n",
            "s21/5.pgm\n",
            "Path\n",
            "s21/6.pgm\n",
            "Path\n",
            "s21/7.pgm\n",
            "Path\n",
            "s21/8.pgm\n",
            "Path\n",
            "s21/9.pgm\n",
            "Path\n",
            "s21/10.pgm\n",
            "Path\n",
            "s22/1.pgm\n",
            "Path\n",
            "s22/2.pgm\n",
            "Path\n",
            "s22/3.pgm\n",
            "Path\n",
            "s22/4.pgm\n",
            "Path\n",
            "s22/5.pgm\n",
            "Path\n",
            "s22/6.pgm\n",
            "Path\n",
            "s22/7.pgm\n",
            "Path\n",
            "s22/8.pgm\n",
            "Path\n",
            "s22/9.pgm\n",
            "Path\n",
            "s22/10.pgm\n",
            "Path\n",
            "s23/1.pgm\n",
            "Path\n",
            "s23/2.pgm\n",
            "Path\n",
            "s23/3.pgm\n",
            "Path\n",
            "s23/4.pgm\n",
            "Path\n",
            "s23/5.pgm\n",
            "Path\n",
            "s23/6.pgm\n",
            "Path\n",
            "s23/7.pgm\n",
            "Path\n",
            "s23/8.pgm\n",
            "Path\n",
            "s23/9.pgm\n",
            "Path\n",
            "s23/10.pgm\n",
            "Path\n",
            "s24/1.pgm\n",
            "Path\n",
            "s24/2.pgm\n",
            "Path\n",
            "s24/3.pgm\n",
            "Path\n",
            "s24/4.pgm\n",
            "Path\n",
            "s24/5.pgm\n",
            "Path\n",
            "s24/6.pgm\n",
            "Path\n",
            "s24/7.pgm\n",
            "Path\n",
            "s24/8.pgm\n",
            "Path\n",
            "s24/9.pgm\n",
            "Path\n",
            "s24/10.pgm\n",
            "Path\n",
            "s25/1.pgm\n",
            "Path\n",
            "s25/2.pgm\n",
            "Path\n",
            "s25/3.pgm\n",
            "Path\n",
            "s25/4.pgm\n",
            "Path\n",
            "s25/5.pgm\n",
            "Path\n",
            "s25/6.pgm\n",
            "Path\n",
            "s25/7.pgm\n",
            "Path\n",
            "s25/8.pgm\n",
            "Path\n",
            "s25/9.pgm\n",
            "Path\n",
            "s25/10.pgm\n",
            "Path\n",
            "s26/1.pgm\n",
            "Path\n",
            "s26/2.pgm\n",
            "Path\n",
            "s26/3.pgm\n",
            "Path\n",
            "s26/4.pgm\n",
            "Path\n",
            "s26/5.pgm\n",
            "Path\n",
            "s26/6.pgm\n",
            "Path\n",
            "s26/7.pgm\n",
            "Path\n",
            "s26/8.pgm\n",
            "Path\n",
            "s26/9.pgm\n",
            "Path\n",
            "s26/10.pgm\n",
            "Path\n",
            "s27/1.pgm\n",
            "Path\n",
            "s27/2.pgm\n",
            "Path\n",
            "s27/3.pgm\n",
            "Path\n",
            "s27/4.pgm\n",
            "Path\n",
            "s27/5.pgm\n",
            "Path\n",
            "s27/6.pgm\n",
            "Path\n",
            "s27/7.pgm\n",
            "Path\n",
            "s27/8.pgm\n",
            "Path\n",
            "s27/9.pgm\n",
            "Path\n",
            "s27/10.pgm\n",
            "Path\n",
            "s28/1.pgm\n",
            "Path\n",
            "s28/2.pgm\n",
            "Path\n",
            "s28/3.pgm\n",
            "Path\n",
            "s28/4.pgm\n",
            "Path\n",
            "s28/5.pgm\n",
            "Path\n",
            "s28/6.pgm\n",
            "Path\n",
            "s28/7.pgm\n",
            "Path\n",
            "s28/8.pgm\n",
            "Path\n",
            "s28/9.pgm\n",
            "Path\n",
            "s28/10.pgm\n",
            "Path\n",
            "s29/1.pgm\n",
            "Path\n",
            "s29/2.pgm\n",
            "Path\n",
            "s29/3.pgm\n",
            "Path\n",
            "s29/4.pgm\n",
            "Path\n",
            "s29/5.pgm\n",
            "Path\n",
            "s29/6.pgm\n",
            "Path\n",
            "s29/7.pgm\n",
            "Path\n",
            "s29/8.pgm\n",
            "Path\n",
            "s29/9.pgm\n",
            "Path\n",
            "s29/10.pgm\n",
            "Path\n",
            "s30/1.pgm\n",
            "Path\n",
            "s30/2.pgm\n",
            "Path\n",
            "s30/3.pgm\n",
            "Path\n",
            "s30/4.pgm\n",
            "Path\n",
            "s30/5.pgm\n",
            "Path\n",
            "s30/6.pgm\n",
            "Path\n",
            "s30/7.pgm\n",
            "Path\n",
            "s30/8.pgm\n",
            "Path\n",
            "s30/9.pgm\n",
            "Path\n",
            "s30/10.pgm\n",
            "Path\n",
            "s31/1.pgm\n",
            "Path\n",
            "s31/2.pgm\n",
            "Path\n",
            "s31/3.pgm\n",
            "Path\n",
            "s31/4.pgm\n",
            "Path\n",
            "s31/5.pgm\n",
            "Path\n",
            "s31/6.pgm\n",
            "Path\n",
            "s31/7.pgm\n",
            "Path\n",
            "s31/8.pgm\n",
            "Path\n",
            "s31/9.pgm\n",
            "Path\n",
            "s31/10.pgm\n",
            "Path\n",
            "s32/1.pgm\n",
            "Path\n",
            "s32/2.pgm\n",
            "Path\n",
            "s32/3.pgm\n",
            "Path\n",
            "s32/4.pgm\n",
            "Path\n",
            "s32/5.pgm\n",
            "Path\n",
            "s32/6.pgm\n",
            "Path\n",
            "s32/7.pgm\n",
            "Path\n",
            "s32/8.pgm\n",
            "Path\n",
            "s32/9.pgm\n",
            "Path\n",
            "s32/10.pgm\n",
            "Path\n",
            "s33/1.pgm\n",
            "Path\n",
            "s33/2.pgm\n",
            "Path\n",
            "s33/3.pgm\n",
            "Path\n",
            "s33/4.pgm\n",
            "Path\n",
            "s33/5.pgm\n",
            "Path\n",
            "s33/6.pgm\n",
            "Path\n",
            "s33/7.pgm\n",
            "Path\n",
            "s33/8.pgm\n",
            "Path\n",
            "s33/9.pgm\n",
            "Path\n",
            "s33/10.pgm\n",
            "Path\n",
            "s34/1.pgm\n",
            "Path\n",
            "s34/2.pgm\n",
            "Path\n",
            "s34/3.pgm\n",
            "Path\n",
            "s34/4.pgm\n",
            "Path\n",
            "s34/5.pgm\n",
            "Path\n",
            "s34/6.pgm\n",
            "Path\n",
            "s34/7.pgm\n",
            "Path\n",
            "s34/8.pgm\n",
            "Path\n",
            "s34/9.pgm\n",
            "Path\n",
            "s34/10.pgm\n",
            "Path\n",
            "s35/1.pgm\n",
            "Path\n",
            "s35/2.pgm\n",
            "Path\n",
            "s35/3.pgm\n",
            "Path\n",
            "s35/4.pgm\n",
            "Path\n",
            "s35/5.pgm\n",
            "Path\n",
            "s35/6.pgm\n",
            "Path\n",
            "s35/7.pgm\n",
            "Path\n",
            "s35/8.pgm\n",
            "Path\n",
            "s35/9.pgm\n",
            "Path\n",
            "s35/10.pgm\n",
            "Path\n",
            "s36/1.pgm\n",
            "Path\n",
            "s36/2.pgm\n",
            "Path\n",
            "s36/3.pgm\n",
            "Path\n",
            "s36/4.pgm\n",
            "Path\n",
            "s36/5.pgm\n",
            "Path\n",
            "s36/6.pgm\n",
            "Path\n",
            "s36/7.pgm\n",
            "Path\n",
            "s36/8.pgm\n",
            "Path\n",
            "s36/9.pgm\n",
            "Path\n",
            "s36/10.pgm\n",
            "Path\n",
            "s37/1.pgm\n",
            "Path\n",
            "s37/2.pgm\n",
            "Path\n",
            "s37/3.pgm\n",
            "Path\n",
            "s37/4.pgm\n",
            "Path\n",
            "s37/5.pgm\n",
            "Path\n",
            "s37/6.pgm\n",
            "Path\n",
            "s37/7.pgm\n",
            "Path\n",
            "s37/8.pgm\n",
            "Path\n",
            "s37/9.pgm\n",
            "Path\n",
            "s37/10.pgm\n",
            "Path\n",
            "s38/1.pgm\n",
            "Path\n",
            "s38/2.pgm\n",
            "Path\n",
            "s38/3.pgm\n",
            "Path\n",
            "s38/4.pgm\n",
            "Path\n",
            "s38/5.pgm\n",
            "Path\n",
            "s38/6.pgm\n",
            "Path\n",
            "s38/7.pgm\n",
            "Path\n",
            "s38/8.pgm\n",
            "Path\n",
            "s38/9.pgm\n",
            "Path\n",
            "s38/10.pgm\n",
            "Path\n",
            "s39/1.pgm\n",
            "Path\n",
            "s39/2.pgm\n",
            "Path\n",
            "s39/3.pgm\n",
            "Path\n",
            "s39/4.pgm\n",
            "Path\n",
            "s39/5.pgm\n",
            "Path\n",
            "s39/6.pgm\n",
            "Path\n",
            "s39/7.pgm\n",
            "Path\n",
            "s39/8.pgm\n",
            "Path\n",
            "s39/9.pgm\n",
            "Path\n",
            "s39/10.pgm\n",
            "Path\n",
            "s40/1.pgm\n",
            "Path\n",
            "s40/2.pgm\n",
            "Path\n",
            "s40/3.pgm\n",
            "Path\n",
            "s40/4.pgm\n",
            "Path\n",
            "s40/5.pgm\n",
            "Path\n",
            "s40/6.pgm\n",
            "Path\n",
            "s40/7.pgm\n",
            "Path\n",
            "s40/8.pgm\n",
            "Path\n",
            "s40/9.pgm\n",
            "Path\n",
            "s40/10.pgm\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3zR2HiIC4ZlM",
        "outputId": "1dda5263-aba5-4f1c-fef6-e46aaff9392c"
      },
      "source": [
        "Data_matrix = np.array(Data_matrix)\n",
        "print(\"Total data:\")\n",
        "print(Data_matrix.shape)\n",
        "print(Data_matrix)\n",
        "\n",
        "print(\"Labels:\")\n",
        "print(y)\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total data:\n",
            "(400, 10304)\n",
            "[[ 48  49  45 ...  47  46  46]\n",
            " [ 60  60  62 ...  32  34  34]\n",
            " [ 39  44  53 ...  29  26  29]\n",
            " ...\n",
            " [125 119 124 ...  36  39  40]\n",
            " [119 120 120 ...  89  94  85]\n",
            " [125 124 124 ...  36  35  34]]\n",
            "Labels:\n",
            "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a2YLvF2rqzIu"
      },
      "source": [
        "splitting the data:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5MIQCZW1q4zd",
        "outputId": "a59ab378-824d-4263-acf7-0024d9dac488"
      },
      "source": [
        "Testing =  Data_matrix[::2]\n",
        "Training = Data_matrix[1::2]\n",
        "print(\"Training\")\n",
        "print(Training)\n",
        "\n",
        "print(\"Testing\")\n",
        "print(Testing)\n",
        "\n",
        "Training_Labels=[]\n",
        "Original_Testing_Labels=[]\n",
        "for i in range(1,41):\n",
        "  for j in range(1,6):\n",
        "    Training_Labels.append(i)\n",
        "    Original_Testing_Labels.append(i)\n",
        "\n",
        "print(\"Training Labels:\")\n",
        "print(Training_Labels)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training\n",
            "[[ 60  60  62 ...  32  34  34]\n",
            " [ 63  53  35 ...  41  10  24]\n",
            " [ 43  50  41 ... 158 153 169]\n",
            " ...\n",
            " [123 121 126 ...  40  35  42]\n",
            " [125 119 124 ...  36  39  40]\n",
            " [125 124 124 ...  36  35  34]]\n",
            "Testing\n",
            "[[ 48  49  45 ...  47  46  46]\n",
            " [ 39  44  53 ...  29  26  29]\n",
            " [ 64  76  80 ...  35  37  39]\n",
            " ...\n",
            " [128 125 125 ...  85  90  84]\n",
            " [129 127 133 ...  93  93  93]\n",
            " [119 120 120 ...  89  94  85]]\n",
            "Training Labels:\n",
            "[1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 9, 9, 9, 9, 9, 10, 10, 10, 10, 10, 11, 11, 11, 11, 11, 12, 12, 12, 12, 12, 13, 13, 13, 13, 13, 14, 14, 14, 14, 14, 15, 15, 15, 15, 15, 16, 16, 16, 16, 16, 17, 17, 17, 17, 17, 18, 18, 18, 18, 18, 19, 19, 19, 19, 19, 20, 20, 20, 20, 20, 21, 21, 21, 21, 21, 22, 22, 22, 22, 22, 23, 23, 23, 23, 23, 24, 24, 24, 24, 24, 25, 25, 25, 25, 25, 26, 26, 26, 26, 26, 27, 27, 27, 27, 27, 28, 28, 28, 28, 28, 29, 29, 29, 29, 29, 30, 30, 30, 30, 30, 31, 31, 31, 31, 31, 32, 32, 32, 32, 32, 33, 33, 33, 33, 33, 34, 34, 34, 34, 34, 35, 35, 35, 35, 35, 36, 36, 36, 36, 36, 37, 37, 37, 37, 37, 38, 38, 38, 38, 38, 39, 39, 39, 39, 39, 40, 40, 40, 40, 40]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "si0S-_RO3X47"
      },
      "source": [
        "### **PCA function:**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tnoLMaCJ3cO7"
      },
      "source": [
        "def PCA_Prepration(Training):\n",
        "  MeanMatrix=np.array(Training).mean(axis=0)\n",
        "  print(\"Mean Matrix: \")\n",
        "  print(MeanMatrix)\n",
        "  print(\"Mean Matrix shape: \")\n",
        "  print(MeanMatrix.shape)\n",
        "  print(\"\\n *********************************** \\n\")\n",
        "  print(\"Centred Data: \")\n",
        "  Centred_Data=np.array(Training-MeanMatrix)\n",
        "  print(Centred_Data)\n",
        "  print(\"\\n *********************************** \\n\")\n",
        "  print(\"Covariance matrix: \")\n",
        "  Covariance_Matrix=np.cov(Centred_Data.T,bias=True)\n",
        "  print(Covariance_Matrix)\n",
        "  print(\"\\n *********************************** \\n\")\n",
        "  Eigenvalues,EigenVectors=np.linalg.eigh(Covariance_Matrix)\n",
        "  print(\"Eigenvalues: \")\n",
        "  print(Eigenvalues)\n",
        "  print(\"\\n *********************************** \\n\")\n",
        "  print(\"Eigenvectors: \")\n",
        "  print(EigenVectors)\n",
        "  print(\"\\n *********************************** \\n\")\n",
        "  print(\"Sum of total EigenValues\")\n",
        "  SumEigenValues=Eigenvalues.sum()\n",
        "  print(SumEigenValues)\n",
        "  idx = np.argsort(Eigenvalues)[::-1]\n",
        "  Sorted_eigenValues= Eigenvalues[idx]\n",
        "  #Sorted_eigenValues=np.diagflat(Sorted_eigenValues)\n",
        "  Sorted_eigenvectors= EigenVectors[:,idx]\n",
        "\n",
        "  return  Sorted_eigenValues, Sorted_eigenvectors\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T16OxyqjNJGU"
      },
      "source": [
        "def PCA(Alpha):\n",
        "  FractionalSum=0 \n",
        "  FractionalVariance=0\n",
        "  index=0\n",
        "  for i in range(0,len(Sorted_eigenValues)):\n",
        "    FractionalVariance=FractionalSum / SumEigenValues\n",
        "    if  FractionalVariance < Alpha :\n",
        "      index=i\n",
        "      FractionalSum+=Sorted_eigenValues[i]\n",
        "    else:\n",
        "      break\n",
        " \n",
        "  print(\"Fractional Variance\")\n",
        "  print(FractionalVariance)\n",
        "  print(\"r= \",index)\n",
        "          \n",
        "\n",
        "  print(\"\\n *********************************** \\n\")\n",
        "  Reduced_Eigenvectors=Sorted_eigenvectors[:, 0:index+1]\n",
        "  print(\"Reduced EigenVector= \")\n",
        "  print(Reduced_Eigenvectors)\n",
        "  print(Reduced_Eigenvectors.shape)\n",
        "  print(\"\\n *********************************** \\n\")\n",
        "\n",
        "  Reduced_EigenvectorsT=np.transpose(Reduced_Eigenvectors)\n",
        "  print(\"projection matrix= \")\n",
        "  print(Reduced_EigenvectorsT) \n",
        "\n",
        "  print(\"\\n *********************************** \\n\")\n",
        "  print(\"Projected Training matrix = \")\n",
        "  projected_training=np.dot(Centred_Data,Reduced_Eigenvectors)\n",
        "  print(projected_training)\n",
        "\n",
        "  print(\"\\n *********************************** \\n\")\n",
        "  Temp_Testing=np.subtract(Testing,Testing.mean(axis=0))\n",
        "  print(\"Testing\",Testing)\n",
        "  print(\"Temp_Testing\",Temp_Testing)\n",
        "  projected_testing=np.dot(Temp_Testing,Reduced_Eigenvectors)\n",
        "  print(\"Projected Testing matrix = \")\n",
        "  print(projected_testing)\n",
        "  print(\"\\n *********************************** \\n\")\n",
        " \n",
        "  return projected_training,projected_testing"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bS93axkAK2qA",
        "outputId": "0f260cd2-0151-4bb8-98af-119440825bb4"
      },
      "source": [
        "Sorted_eigenValues, Sorted_eigenvectors=PCA_Prepration(Training)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mean Matrix: \n",
            "[85.12  84.89  85.165 ... 77.24  74.335 73.37 ]\n",
            "Mean Matrix shape: \n",
            "(10304,)\n",
            "\n",
            " *********************************** \n",
            "\n",
            "Centred Data: \n",
            "[[-25.12  -24.89  -23.165 ... -45.24  -40.335 -39.37 ]\n",
            " [-22.12  -31.89  -50.165 ... -36.24  -64.335 -49.37 ]\n",
            " [-42.12  -34.89  -44.165 ...  80.76   78.665  95.63 ]\n",
            " ...\n",
            " [ 37.88   36.11   40.835 ... -37.24  -39.335 -31.37 ]\n",
            " [ 39.88   34.11   38.835 ... -41.24  -35.335 -33.37 ]\n",
            " [ 39.88   39.11   38.835 ... -41.24  -39.335 -39.37 ]]\n",
            "\n",
            " *********************************** \n",
            "\n",
            "Covariance matrix: \n",
            "[[1318.8756   1299.2282   1304.6652   ... -235.7588   -126.0752\n",
            "   -75.5394  ]\n",
            " [1299.2282   1295.5879   1293.30315  ... -218.1036   -112.70315\n",
            "   -64.3043  ]\n",
            " [1304.6652   1293.30315  1306.107775 ... -216.9946    -99.325275\n",
            "   -49.28605 ]\n",
            " ...\n",
            " [-235.7588   -218.1036   -216.9946   ... 2505.0524   1995.4546\n",
            "  1882.7162  ]\n",
            " [-126.0752   -112.70315   -99.325275 ... 1995.4546   1972.392775\n",
            "  1859.56105 ]\n",
            " [ -75.5394    -64.3043    -49.28605  ... 1882.7162   1859.56105\n",
            "  1968.8831  ]]\n",
            "\n",
            " *********************************** \n",
            "\n",
            "Eigenvalues: \n",
            "[-1.80951423e-09 -1.25952449e-09 -9.95268041e-10 ...  1.06569341e+06\n",
            "  2.14179597e+06  2.76884465e+06]\n",
            "\n",
            " *********************************** \n",
            "\n",
            "Eigenvectors: \n",
            "[[ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ... -1.89107867e-02\n",
            "  -1.53617120e-02  1.24555558e-03]\n",
            " [-4.84083897e-01 -2.12232620e-01  1.28297218e-01 ... -1.91177650e-02\n",
            "  -1.51314624e-02  1.26453637e-03]\n",
            " [ 4.85655112e-01 -2.59612941e-01  6.42270142e-02 ... -1.90394178e-02\n",
            "  -1.51619504e-02  1.56464522e-03]\n",
            " ...\n",
            " [ 3.41247115e-05  1.28319043e-02 -2.55686532e-02 ... -1.28745102e-02\n",
            "   9.61111754e-03  8.73724732e-03]\n",
            " [-1.53767104e-02  8.46495884e-03  6.62807118e-03 ... -1.37731826e-02\n",
            "   7.75970197e-03  7.21705083e-03]\n",
            " [ 6.67557976e-03 -2.35056749e-02 -1.70360798e-02 ... -1.43881511e-02\n",
            "   6.92707821e-03  8.40080072e-03]]\n",
            "\n",
            " *********************************** \n",
            "\n",
            "Sum of total EigenValues\n",
            "15955336.343849987\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        },
        "id": "MSmA8vBx4Bal",
        "outputId": "eea10632-33c2-47d0-aa5a-30f63775b93d"
      },
      "source": [
        "print(\"PCA output for Alpha=0.8 :\")\n",
        "projected_training08,projected_testing08=PCA(0.8)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "PCA output for Alpha=0.8 :\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-caea04c7574f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"PCA output for Alpha=0.8 :\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprojected_training08\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mprojected_testing08\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mPCA\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-8-dc3f9b158865>\u001b[0m in \u001b[0;36mPCA\u001b[0;34m(Alpha)\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0mFractionalVariance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m   \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSorted_eigenValues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mFractionalVariance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFractionalSum\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mSumEigenValues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mif\u001b[0m  \u001b[0mFractionalVariance\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mAlpha\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'Sorted_eigenValues' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GXX_U0NgXjGG",
        "outputId": "555babb3-be3a-45c7-b57d-147c7dc6d28c"
      },
      "source": [
        "print(\"PCA output for Alpha=0.85 :\")\n",
        "projected_training085,projected_testing085=PCA(0.85)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "PCA output for Alpha=0.85 :\n",
            "Fractional Variance\n",
            "0.8523113375505037\n",
            "r=  52\n",
            "\n",
            " *********************************** \n",
            "\n",
            "Reduced EigenVector= \n",
            "[[ 0.00124556 -0.01536171 -0.01891079 ... -0.00658215  0.0063633\n",
            "  -0.00188005]\n",
            " [ 0.00126454 -0.01513146 -0.01911777 ... -0.00497546  0.00626057\n",
            "  -0.00089457]\n",
            " [ 0.00156465 -0.01516195 -0.01903942 ... -0.00530911  0.00690086\n",
            "  -0.00163866]\n",
            " ...\n",
            " [ 0.00873725  0.00961112 -0.01287451 ... -0.00490491 -0.01032198\n",
            "  -0.00532878]\n",
            " [ 0.00721705  0.0077597  -0.01377318 ...  0.0029665  -0.00741123\n",
            "  -0.00191385]\n",
            " [ 0.0084008   0.00692708 -0.01438815 ... -0.00282685 -0.00728419\n",
            "  -0.00833635]]\n",
            "(10304, 53)\n",
            "\n",
            " *********************************** \n",
            "\n",
            "projection matrix= \n",
            "[[ 0.00124556  0.00126454  0.00156465 ...  0.00873725  0.00721705\n",
            "   0.0084008 ]\n",
            " [-0.01536171 -0.01513146 -0.01516195 ...  0.00961112  0.0077597\n",
            "   0.00692708]\n",
            " [-0.01891079 -0.01911777 -0.01903942 ... -0.01287451 -0.01377318\n",
            "  -0.01438815]\n",
            " ...\n",
            " [-0.00658215 -0.00497546 -0.00530911 ... -0.00490491  0.0029665\n",
            "  -0.00282685]\n",
            " [ 0.0063633   0.00626057  0.00690086 ... -0.01032198 -0.00741123\n",
            "  -0.00728419]\n",
            " [-0.00188005 -0.00089457 -0.00163866 ... -0.00532878 -0.00191385\n",
            "  -0.00833635]]\n",
            "\n",
            " *********************************** \n",
            "\n",
            "Projected Training matrix = \n",
            "[[-3034.06466934  -636.11936009  -754.66185255 ...  -211.37679619\n",
            "    390.58622224  -110.69501132]\n",
            " [-3258.5750091  -1115.57366797  -123.18181896 ...    59.1186332\n",
            "   -276.66775034    46.9820307 ]\n",
            " [-2560.74280812 -1015.28384869   -96.96261658 ...   264.77692671\n",
            "     52.13283219   126.79425679]\n",
            " ...\n",
            " [ -765.14348983 -1081.3823894  -1546.73535921 ...    50.7544015\n",
            "   -251.29319387   187.73597211]\n",
            " [ -946.29319382 -1011.49713612 -1461.46003308 ...   -70.6204616\n",
            "   -385.10459894    28.15882849]\n",
            " [ -629.54963779  -485.43259309 -2132.02447043 ...  -127.75800831\n",
            "    -22.31426129   194.77217624]]\n",
            "\n",
            " *********************************** \n",
            "\n",
            "Testing [[ 48  49  45 ...  47  46  46]\n",
            " [ 39  44  53 ...  29  26  29]\n",
            " [ 64  76  80 ...  35  37  39]\n",
            " ...\n",
            " [128 125 125 ...  85  90  84]\n",
            " [129 127 133 ...  93  93  93]\n",
            " [119 120 120 ...  89  94  85]]\n",
            "Temp_Testing [[-38.115 -37.265 -41.685 ... -29.5   -31.395 -31.085]\n",
            " [-47.115 -42.265 -33.685 ... -47.5   -51.395 -48.085]\n",
            " [-22.115 -10.265  -6.685 ... -41.5   -40.395 -38.085]\n",
            " ...\n",
            " [ 41.885  38.735  38.315 ...   8.5    12.605   6.915]\n",
            " [ 42.885  40.735  46.315 ...  16.5    15.605  15.915]\n",
            " [ 32.885  33.735  33.315 ...  12.5    16.605   7.915]]\n",
            "Projected Testing matrix = \n",
            "[[-1482.03232432  -926.39577336  1811.15162761 ...   -83.48486826\n",
            "   -114.27542481   -36.65576806]\n",
            " [-2635.7174063   -240.43034591   996.03559702 ...   143.36053971\n",
            "     50.58296994     7.51420117]\n",
            " [-3605.70281733  -676.97111934   126.63257266 ...  -101.50244311\n",
            "     71.88469067   -11.36919172]\n",
            " ...\n",
            " [-1245.99275243 -1537.79227285  -729.84559952 ...    70.65990144\n",
            "   -105.58955147   150.98490922]\n",
            " [-1176.06829143 -1197.48377752  -905.28499663 ...    -5.71888701\n",
            "   -177.41131637   216.96559755]\n",
            " [-1398.50825097 -1214.52887635  -645.23783044 ...     9.30353819\n",
            "    -88.3543422    283.92471443]]\n",
            "\n",
            " *********************************** \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "abz3krjyXplc",
        "outputId": "11617833-0efc-4d98-9d88-f0e05e4c7e9a"
      },
      "source": [
        "print(\"PCA output for Alpha=0.9:\")\n",
        "projected_training09,projected_testing09=PCA(0.9)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "PCA output for Alpha=0.9:\n",
            "Fractional Variance\n",
            "0.9007600309473764\n",
            "r=  76\n",
            "\n",
            " *********************************** \n",
            "\n",
            "Reduced EigenVector= \n",
            "[[ 0.00124556 -0.01536171 -0.01891079 ...  0.00179702 -0.0038579\n",
            "   0.00149348]\n",
            " [ 0.00126454 -0.01513146 -0.01911777 ...  0.00188084 -0.00483295\n",
            "   0.00235076]\n",
            " [ 0.00156465 -0.01516195 -0.01903942 ...  0.00152641 -0.0040227\n",
            "   0.00128325]\n",
            " ...\n",
            " [ 0.00873725  0.00961112 -0.01287451 ...  0.0070125  -0.02963997\n",
            "   0.0032255 ]\n",
            " [ 0.00721705  0.0077597  -0.01377318 ...  0.01557117 -0.02348247\n",
            "   0.01523977]\n",
            " [ 0.0084008   0.00692708 -0.01438815 ...  0.00818988 -0.01151255\n",
            "   0.00688259]]\n",
            "(10304, 77)\n",
            "\n",
            " *********************************** \n",
            "\n",
            "projection matrix= \n",
            "[[ 0.00124556  0.00126454  0.00156465 ...  0.00873725  0.00721705\n",
            "   0.0084008 ]\n",
            " [-0.01536171 -0.01513146 -0.01516195 ...  0.00961112  0.0077597\n",
            "   0.00692708]\n",
            " [-0.01891079 -0.01911777 -0.01903942 ... -0.01287451 -0.01377318\n",
            "  -0.01438815]\n",
            " ...\n",
            " [ 0.00179702  0.00188084  0.00152641 ...  0.0070125   0.01557117\n",
            "   0.00818988]\n",
            " [-0.0038579  -0.00483295 -0.0040227  ... -0.02963997 -0.02348247\n",
            "  -0.01151255]\n",
            " [ 0.00149348  0.00235076  0.00128325 ...  0.0032255   0.01523977\n",
            "   0.00688259]]\n",
            "\n",
            " *********************************** \n",
            "\n",
            "Projected Training matrix = \n",
            "[[-3034.06466934  -636.11936009  -754.66185255 ...   130.91990192\n",
            "    152.58425129  -179.55436029]\n",
            " [-3258.5750091  -1115.57366797  -123.18181896 ...   140.1040386\n",
            "    192.54428714  -134.30625764]\n",
            " [-2560.74280812 -1015.28384869   -96.96261658 ...    18.88359316\n",
            "   -177.44757868  -189.94013374]\n",
            " ...\n",
            " [ -765.14348983 -1081.3823894  -1546.73535921 ...  -117.95038671\n",
            "    100.32424184  -201.56080205]\n",
            " [ -946.29319382 -1011.49713612 -1461.46003308 ...    76.59318425\n",
            "    -87.53803807  -426.28638891]\n",
            " [ -629.54963779  -485.43259309 -2132.02447043 ...   -81.2165922\n",
            "    -43.97215039  -135.16796695]]\n",
            "\n",
            " *********************************** \n",
            "\n",
            "Testing [[ 48  49  45 ...  47  46  46]\n",
            " [ 39  44  53 ...  29  26  29]\n",
            " [ 64  76  80 ...  35  37  39]\n",
            " ...\n",
            " [128 125 125 ...  85  90  84]\n",
            " [129 127 133 ...  93  93  93]\n",
            " [119 120 120 ...  89  94  85]]\n",
            "Temp_Testing [[-38.115 -37.265 -41.685 ... -29.5   -31.395 -31.085]\n",
            " [-47.115 -42.265 -33.685 ... -47.5   -51.395 -48.085]\n",
            " [-22.115 -10.265  -6.685 ... -41.5   -40.395 -38.085]\n",
            " ...\n",
            " [ 41.885  38.735  38.315 ...   8.5    12.605   6.915]\n",
            " [ 42.885  40.735  46.315 ...  16.5    15.605  15.915]\n",
            " [ 32.885  33.735  33.315 ...  12.5    16.605   7.915]]\n",
            "Projected Testing matrix = \n",
            "[[-1482.03232432  -926.39577336  1811.15162761 ...   -43.89729205\n",
            "    146.62611387    85.65241279]\n",
            " [-2635.7174063   -240.43034591   996.03559702 ...  -304.50014651\n",
            "     29.57599178   -68.10774623]\n",
            " [-3605.70281733  -676.97111934   126.63257266 ...    15.22392329\n",
            "    147.26144994   -94.40013644]\n",
            " ...\n",
            " [-1245.99275243 -1537.79227285  -729.84559952 ...   -22.66817872\n",
            "     97.23196926   -63.63406357]\n",
            " [-1176.06829143 -1197.48377752  -905.28499663 ...    26.40453425\n",
            "    112.52739689   241.08518861]\n",
            " [-1398.50825097 -1214.52887635  -645.23783044 ...   -33.97472159\n",
            "     94.3623779    213.75613567]]\n",
            "\n",
            " *********************************** \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LMXzPv-jX1w4",
        "outputId": "237ae749-35c4-450e-9622-33171d4ee3aa"
      },
      "source": [
        "print(\"PCA output for Alpha=0.95 :\")\n",
        "projected_training095,projected_testing095=PCA(0.95)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "PCA output for Alpha=0.95 :\n",
            "Fractional Variance\n",
            "0.9500861567347986\n",
            "r=  115\n",
            "\n",
            " *********************************** \n",
            "\n",
            "Reduced EigenVector= \n",
            "[[ 0.00124556 -0.01536171 -0.01891079 ... -0.0105497  -0.00116262\n",
            "  -0.00499452]\n",
            " [ 0.00126454 -0.01513146 -0.01911777 ... -0.0063317  -0.00192066\n",
            "  -0.00479632]\n",
            " [ 0.00156465 -0.01516195 -0.01903942 ... -0.00767535 -0.00365636\n",
            "  -0.00746669]\n",
            " ...\n",
            " [ 0.00873725  0.00961112 -0.01287451 ...  0.00414923  0.00148975\n",
            "  -0.01489488]\n",
            " [ 0.00721705  0.0077597  -0.01377318 ... -0.00193868 -0.0010741\n",
            "  -0.02912841]\n",
            " [ 0.0084008   0.00692708 -0.01438815 ... -0.0059235  -0.00401374\n",
            "  -0.038607  ]]\n",
            "(10304, 116)\n",
            "\n",
            " *********************************** \n",
            "\n",
            "projection matrix= \n",
            "[[ 0.00124556  0.00126454  0.00156465 ...  0.00873725  0.00721705\n",
            "   0.0084008 ]\n",
            " [-0.01536171 -0.01513146 -0.01516195 ...  0.00961112  0.0077597\n",
            "   0.00692708]\n",
            " [-0.01891079 -0.01911777 -0.01903942 ... -0.01287451 -0.01377318\n",
            "  -0.01438815]\n",
            " ...\n",
            " [-0.0105497  -0.0063317  -0.00767535 ...  0.00414923 -0.00193868\n",
            "  -0.0059235 ]\n",
            " [-0.00116262 -0.00192066 -0.00365636 ...  0.00148975 -0.0010741\n",
            "  -0.00401374]\n",
            " [-0.00499452 -0.00479632 -0.00746669 ... -0.01489488 -0.02912841\n",
            "  -0.038607  ]]\n",
            "\n",
            " *********************************** \n",
            "\n",
            "Projected Training matrix = \n",
            "[[-3.03406467e+03 -6.36119360e+02 -7.54661853e+02 ... -3.08057490e+01\n",
            "  -2.58982225e+00 -6.97242948e+01]\n",
            " [-3.25857501e+03 -1.11557367e+03 -1.23181819e+02 ...  9.66888931e+01\n",
            "  -2.50044123e+01  2.69392057e+01]\n",
            " [-2.56074281e+03 -1.01528385e+03 -9.69626166e+01 ... -6.28813932e+01\n",
            "  -8.15423372e+00  2.01877834e+02]\n",
            " ...\n",
            " [-7.65143490e+02 -1.08138239e+03 -1.54673536e+03 ... -7.56261108e+01\n",
            "  -5.13158894e+01  1.67011694e+02]\n",
            " [-9.46293194e+02 -1.01149714e+03 -1.46146003e+03 ... -1.92929177e+02\n",
            "  -5.40233056e+01  7.01897441e+01]\n",
            " [-6.29549638e+02 -4.85432593e+02 -2.13202447e+03 ...  5.96073637e+01\n",
            "   2.84556977e+01  1.08453775e+00]]\n",
            "\n",
            " *********************************** \n",
            "\n",
            "Testing [[ 48  49  45 ...  47  46  46]\n",
            " [ 39  44  53 ...  29  26  29]\n",
            " [ 64  76  80 ...  35  37  39]\n",
            " ...\n",
            " [128 125 125 ...  85  90  84]\n",
            " [129 127 133 ...  93  93  93]\n",
            " [119 120 120 ...  89  94  85]]\n",
            "Temp_Testing [[-38.115 -37.265 -41.685 ... -29.5   -31.395 -31.085]\n",
            " [-47.115 -42.265 -33.685 ... -47.5   -51.395 -48.085]\n",
            " [-22.115 -10.265  -6.685 ... -41.5   -40.395 -38.085]\n",
            " ...\n",
            " [ 41.885  38.735  38.315 ...   8.5    12.605   6.915]\n",
            " [ 42.885  40.735  46.315 ...  16.5    15.605  15.915]\n",
            " [ 32.885  33.735  33.315 ...  12.5    16.605   7.915]]\n",
            "Projected Testing matrix = \n",
            "[[-1482.03232432  -926.39577336  1811.15162761 ...   -34.36788665\n",
            "     16.00720521   -15.48671326]\n",
            " [-2635.7174063   -240.43034591   996.03559702 ...    23.85829836\n",
            "     -8.55321817    63.84704465]\n",
            " [-3605.70281733  -676.97111934   126.63257266 ...   -19.32331892\n",
            "     68.97905575   -30.21639639]\n",
            " ...\n",
            " [-1245.99275243 -1537.79227285  -729.84559952 ...    93.18619283\n",
            "     83.98682132    10.7933305 ]\n",
            " [-1176.06829143 -1197.48377752  -905.28499663 ...    12.65042861\n",
            "    106.40966446    16.52232043]\n",
            " [-1398.50825097 -1214.52887635  -645.23783044 ...   -64.85873722\n",
            "     -4.74960527    42.22518234]]\n",
            "\n",
            " *********************************** \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VA3SU5Ad-Sw7"
      },
      "source": [
        "def Label_prediction(k,ProjectedTraining , ProjectedTesting):\n",
        "\n",
        "  model = KNeighborsClassifier(n_neighbors=k)\n",
        "  model.fit(ProjectedTraining,np.array(Training_Labels))\n",
        "  Tested_Labels= model.predict(ProjectedTesting)\n",
        "\n",
        "  return Tested_Labels"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qTjahKsqiEFq",
        "outputId": "86caacf0-8f0a-4cb3-8325-10373856d79a"
      },
      "source": [
        "print(\"Tested labels for 0.8=\")\n",
        "Tested_Labels08=Label_prediction (1,projected_training08,projected_testing08)\n",
        "print(Tested_Labels08)\n",
        "\n",
        "print(\"\\n *********************************** \\n\")\n",
        "\n",
        "print(\"Tested labels for 0.85=\")\n",
        "Tested_Labels085=Label_prediction (1,projected_training085,projected_testing085)\n",
        "print(Tested_Labels085)\n",
        "\n",
        "print(\"\\n *********************************** \\n\")\n",
        "\n",
        "print(\"Tested labels for 0.9=\")\n",
        "Tested_Labels09=Label_prediction (1,projected_training09,projected_testing09)\n",
        "print(Tested_Labels09)\n",
        "\n",
        "print(\"\\n *********************************** \\n\")\n",
        "\n",
        "print(\"Tested labels for 0.95=\")\n",
        "Tested_Labels095=Label_prediction (1,projected_training095,projected_testing095)\n",
        "print(Tested_Labels095)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tested labels for 0.8=\n",
            "[16  2  1  1  1  2  2  2  2  2  3  3  3  3  3  4  4  4  4  4  5  5  5  5\n",
            "  5  6  6  6  6  6  7  7  7  7  7  8  8  8  8  8  9  9  9  9  9 10 10 10\n",
            " 10 38 11 11 11 11 11 12 12 12 12 12 13 13 13 13 13 14 14 14 14 14 15 15\n",
            " 15 15 15 16 16 16 16 16 17 17 17 17 17 18 18 18 18 18 19 19 19 19 36 20\n",
            " 20  3 20 20 21 21 21 21 21 22 22 22 22 22 23 23 23 23 23 24 24 24 24 24\n",
            " 25 25 25 25 25 26 26 26 26 26 27 27 27 27 27 28 28 28 28 28 29 29 29 29\n",
            " 29 30 30 30 30 30 31 31 31 21 31 32 32 32  2 32 33 33 33 33 33 34 34 34\n",
            " 34 34 40 15 35 35 35  7 36  7 36 36 37 37 37 37 37 38 38 38 38 38 39 39\n",
            " 39 39 39 40 40  5  5  5]\n",
            "\n",
            " *********************************** \n",
            "\n",
            "Tested labels for 0.85=\n",
            "[16  2  1  1  1  2  2  2  2  2  3  3  3  3  3  4  4  4  4  4  5  5  5  5\n",
            "  5  6  6  6  6  6  7  7  7  7  7  8  8  8  8  8  9  9  9  9  9 10 10 10\n",
            " 10 38 11 11 11 11 11 12 12 12 12 12 13 13 13 13 13 14 14 14 14 14 15 15\n",
            " 15 15 15 16 16 16 16 16 17 17 17 17 17 18 18 18 18 18 19 19 19 19 36 20\n",
            " 20  3 20 20 21 21 21 21 21 22 22 22 22 22 23 23 23 23 23 24 24 24 24 24\n",
            " 25 25 25 25 25 26 26 26 26 26 27 27 27 27 27 28 28 28 28 28 29 29 29 29\n",
            " 29 30 30 30 30 30 31 31 31 21 31 32 32 32  2 32 33 33 33 33 33 34 34 34\n",
            " 34 34 40 35 35 35 35  7 36  7 36 36 37 37 37 37 37 38 38 38 38 38 39 39\n",
            " 39 39 39 40 40  5  5  5]\n",
            "\n",
            " *********************************** \n",
            "\n",
            "Tested labels for 0.9=\n",
            "[16  2  1  1  1  2  2  2  2  2  3  3  3  3  3  4  4  4  4  4  5  5  5  5\n",
            "  5  6  6  6  6  6  7  7  7  7  7  8  8  8  8  8  9  9  9  9  9 10 10 10\n",
            " 10 38 11 11 11 11 11 12 12 12 12 12 13 13 13 13 13 14 14 14 14 14 15 15\n",
            " 15 15 15 16 16 16 16 16 17 17 17 17 17 18 18 18 18 18 19 19 19 19  8 20\n",
            " 20  3 20 20 21 21 21 21 21 22 22 22 22 22 23 23 23 23 23 24 24 24 24 24\n",
            " 25 25 25 25 25 26 26 26 26 26 27 27 27 27 27 28 28 28 28 28 29 29 29 29\n",
            " 29 30 30 30 30 30 31 31 31 30 31 32 32 32  2 32 33 33 33 33 33 34 34 34\n",
            " 34 34 40 35 35 35 35 36 36  7 36 36 37 37 37 37 37 38 38 38 38 38 39 39\n",
            " 39 39 39 40 40  5  5  5]\n",
            "\n",
            " *********************************** \n",
            "\n",
            "Tested labels for 0.95=\n",
            "[16  2  1  1  1  2  2  2  2  2  3  3  3  3  3  4  4  4  4  4  5  5  5  5\n",
            "  5  6  6  6  6  6  7  7  7  7  7  8  8  8  8  8  9  9  9  9  9 10 10 10\n",
            " 10 38 11 11 11 11 11 12 12 12 12 12 13 13 13 13 13 14 14 14 14 14 15 15\n",
            " 15 15 15 16 16 16 16 16 17 17 17 17 17 18 18 18 18 18 19 19 19 19  8 20\n",
            " 20  4 20 20 21 21 21 21 21 22 22 22 22 22 23 23 23 23 23 24 24 24 24 24\n",
            " 25 25 25 25 25 26 26 26 26 26 27 27 27 27 27 28 28 28 28 28 29 29 29 29\n",
            " 29 30 30 30 30 30 31 31 31 30 31 32 32 32  2 32 33 33 33 33 33 34 34 34\n",
            " 34 34 40 35 35 35 35 36 36  7 36 36 37 37 37 37 37 38 38 38 38 23 39 39\n",
            " 39 39 39 40 40  5  5  5]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GbnNnASyG7Ny",
        "outputId": "b8558c8a-8ea8-4f39-c689-b7c6caa9ead5"
      },
      "source": [
        " print(\"Accuracy of 0.8 =\")\n",
        " Accuracy08 = accuracy_score(Original_Testing_Labels, Tested_Labels08)\n",
        " print(Accuracy08*100,\"%\")\n",
        "\n",
        " print(\"Accuracy of 0.85 =\")\n",
        " Accuracy085 = accuracy_score(Original_Testing_Labels, Tested_Labels085)\n",
        " print(Accuracy085*100,\"%\")  \n",
        "\n",
        " print(\"Accuracy of 0.9 =\")\n",
        " Accuracy09 = accuracy_score(Original_Testing_Labels, Tested_Labels09)\n",
        " print(Accuracy09*100,\"%\")\n",
        "\n",
        " print(\"Accuracy of 0.95 =\")\n",
        " Accuracy095= accuracy_score(Original_Testing_Labels, Tested_Labels095)\n",
        " print(Accuracy095*100,\"%\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of 0.8 =\n",
            "93.0 %\n",
            "Accuracy of 0.85 =\n",
            "93.5 %\n",
            "Accuracy of 0.9 =\n",
            "94.0 %\n",
            "Accuracy of 0.95 =\n",
            "93.5 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OJf7wDDdtqL_"
      },
      "source": [
        "\n",
        "### **LDA**\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iMTeDDP1t3b7",
        "outputId": "f536eb23-cc6f-4685-9473-7b1c039ddc6b"
      },
      "source": [
        "#1\n",
        "ListOfClasses=[]\n",
        "for i in range(0,40):\n",
        "  ListOfClasses.append(Training[5*i:5*(i+1),:])\n",
        "\n",
        "  \n",
        "  \n",
        "#print(ListOfClasses)\n",
        "#2\n",
        "ListOfMeans=[]\n",
        "for i in range(0,40):\n",
        "  ListOfMeans.append(np.array(ListOfClasses[i]).mean(axis=0))\n",
        "\n",
        "print(\"List of means length : \",len(ListOfMeans))  \n",
        "print(\"List of means : \",ListOfMeans)\n",
        "\n",
        "#3\n",
        "OverallMean=np.array(Training).mean(axis=0)\n",
        "print(\"Overall mean =\",OverallMean)\n",
        "Sb=np.zeros((10304,10304))\n",
        "for i in range(0,40):\n",
        "  expression=(np.outer((ListOfMeans[i]-OverallMean),np.array((ListOfMeans[i]-OverallMean)).T))\n",
        "  Sb=Sb+ expression\n",
        "Sb=5*Sb  \n",
        "print(\"sb= \",Sb)\n",
        "\n",
        "#4\n",
        "ListOfCentredData=[]\n",
        "for i in range(0,40):\n",
        "  ListOfCentredData.append(ListOfClasses[i]-np.array(ListOfMeans[i]).T)\n",
        "\n",
        "print(\"List of centred data \",ListOfCentredData)\n",
        "\n",
        "#5\n",
        "ListOfScatterMatrcies=np.zeros((10304,10304))\n",
        "for j in range(0,40):\n",
        " expression=np.dot(np.array(ListOfCentredData[j]).T,np.array(ListOfCentredData[j]))\n",
        " ListOfScatterMatrcies=ListOfScatterMatrcies+expression\n",
        "   \n",
        "print(\"S= \",ListOfScatterMatrcies.shape)\n",
        "print(ListOfScatterMatrcies)\n",
        "\n",
        "\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "List of means length :  40\n",
            "List of means :  [array([48.8, 48. , 40.6, ..., 62.2, 56. , 59.4]), array([35.2, 35.8, 35.6, ..., 71.8, 71.6, 71.6]), array([105.2, 104. , 107.4, ...,  50. ,  48.4,  50. ]), array([118.6, 118.8, 118. , ...,  70.8,  69.4,  69.2]), array([128.8, 129. , 127.8, ...,  72.6,  71.8,  72.8]), array([153.4, 152.8, 152.2, ..., 103.6, 103.8, 103. ]), array([56.6, 57.2, 57.6, ..., 64. , 65. , 65.4]), array([122. , 118.6, 119.8, ...,  59.8,  56.8,  59. ]), array([109.8, 111.4, 110.4, ...,  84. ,  82.4,  83.2]), array([134.2, 130. , 132.6, ...,  26. ,  30.4,  32.4]), array([46.4, 47. , 46.4, ..., 34. , 34. , 37.6]), array([104.6, 106. , 105.4, ...,  38.8,  40.6,  33. ]), array([107.6, 109.2, 108. , ...,  20.6,  25.8,  23.8]), array([ 45.8,  47.2,  46.8, ..., 142.2, 142.6, 123.4]), array([72.4, 72.2, 71.4, ..., 71.8, 49. , 54. ]), array([60. , 59. , 61.4, ..., 64.6, 64.6, 60.4]), array([49.4, 49.6, 51.4, ..., 42.2, 46.8, 46. ]), array([121.2, 120.6, 122.2, ...,  73.6,  74. ,  73.4]), array([49.6, 46.8, 50.4, ..., 37.8, 40.6, 35.4]), array([111. , 111.8, 112. , ...,  35. ,  38.6,  36.2]), array([103.6, 101.4, 102.4, ..., 155. , 146.8, 154.4]), array([ 55.4,  55.4,  56.8, ..., 175.8, 124.8, 128.8]), array([122.2, 121.2, 121.8, ...,  77.2,  82.4,  83.6]), array([36.2, 38.2, 38.4, ..., 87. , 51.4, 48. ]), array([121.6, 122.8, 121. , ...,  93.6,  99.8,  92.6]), array([111. , 109. , 109.8, ...,  58.4,  59.2,  61.4]), array([41.6, 43.4, 40.4, ..., 26. , 21.6, 25. ]), array([94.2, 93.8, 93. , ..., 74.2, 73. , 66. ]), array([102.4, 104. , 100.8, ...,  65.2,  66.2,  65.6]), array([109.4, 109.4, 109.8, ...,  83.6,  83.4,  84.6]), array([ 59.2,  62.2,  60.8, ..., 185.6, 165. , 156. ]), array([37. , 36.8, 35.8, ..., 27.8, 28.8, 26. ]), array([ 85. ,  85.2,  87.8, ..., 115.6, 109.4, 126.2]), array([ 24.6,  23.6,  24.8, ..., 185.4, 185.4, 185. ]), array([ 89.8,  90.6,  93. , ..., 115.6, 113.2, 105. ]), array([47. , 43.6, 48.6, ..., 56.8, 60. , 56. ]), array([63.6, 64.4, 63.6, ..., 49.6, 57. , 50. ]), array([109.8, 108.6, 109.6, ...,  68.2,  68. ,  65. ]), array([ 84.6,  83.4,  85.2, ..., 115.8, 119.8, 117.4]), array([126. , 123.6, 125.8, ...,  47.8,  46. ,  49. ])]\n",
            "Overall mean = [85.12  84.89  85.165 ... 77.24  74.335 73.37 ]\n",
            "sb=  [[235278.32  232717.44  233560.64  ... -43174.56  -21703.44  -15646.88 ]\n",
            " [232717.44  230668.78  231142.03  ... -40923.52  -20191.43  -14642.46 ]\n",
            " [233560.64  231142.03  232523.155 ... -39926.72  -18941.855 -13273.41 ]\n",
            " ...\n",
            " [-43174.56  -40923.52  -39926.72  ... 360976.48  315665.12  312321.04 ]\n",
            " [-21703.44  -20191.43  -18941.855 ... 315665.12  294892.955 289157.81 ]\n",
            " [-15646.88  -14642.46  -13273.41  ... 312321.04  289157.81  289627.82 ]]\n",
            "List of centred data  [array([[ 11.2,  12. ,  21.4, ..., -30.2, -22. , -25.4],\n",
            "       [ 14.2,   5. ,  -5.6, ..., -21.2, -46. , -35.4],\n",
            "       [ -5.8,   2. ,   0.4, ...,  95.8,  97. , 109.6],\n",
            "       [ -4.8,  -5. ,  -8.6, ..., -19.2, -13. , -22.4],\n",
            "       [-14.8, -14. ,  -7.6, ..., -25.2, -16. , -26.4]]), array([[  1.8,  -0.8,  -0.6, ..., -45.8, -43.6, -43.6],\n",
            "       [ -1.2,   0.2,  -0.6, ..., -39.8, -46.6, -46.6],\n",
            "       [ -1.2,  -0.8,  -0.6, ..., -40.8, -47.6, -47.6],\n",
            "       [ -1.2,   3.2,  -0.6, ...,  63.2,  66.4,  76.4],\n",
            "       [  1.8,  -1.8,   2.4, ...,  63.2,  71.4,  61.4]]), array([[ -5.2,  -5. ,   0.6, ...,  -6. ,  -6.4,  -6. ],\n",
            "       [ -0.2,  -2. ,   0.6, ...,  -8. , -13.4, -13. ],\n",
            "       [  4.8,   2. ,   1.6, ...,  -1. ,   4.6,   3. ],\n",
            "       [  1.8,   0. ,   1.6, ...,   8. ,   7.6,   7. ],\n",
            "       [ -1.2,   5. ,  -4.4, ...,   7. ,   7.6,   9. ]]), array([[ -2.6,  -6.8,  -3. , ..., -19.8, -14.4, -15.2],\n",
            "       [  0.4,   2.2,   1. , ...,  11.2,   8.6,  10.8],\n",
            "       [  2.4,   4.2,   3. , ...,  17.2,  13.6,   8.8],\n",
            "       [ -0.6,  -4.8,  -1. , ..., -12.8, -15.4, -17.2],\n",
            "       [  0.4,   5.2,   0. , ...,   4.2,   7.6,  12.8]]), array([[  1.2,   3. ,   1.2, ..., -19.6, -21.8, -20.8],\n",
            "       [  1.2,   4. ,   1.2, ..., -18.6, -17.8, -16.8],\n",
            "       [ -0.8,  -1. ,   0.2, ...,  14.4,  11.2,  13.2],\n",
            "       [  3.2,  -2. ,   0.2, ...,  12.4,  11.2,  12.2],\n",
            "       [ -4.8,  -4. ,  -2.8, ...,  11.4,  17.2,  12.2]]), array([[ -9.4,  -8.8,  -7.2, ..., -27.6, -25.8, -21. ],\n",
            "       [  2.6,   5.2,   2.8, ...,   9.4,   6.2,   5. ],\n",
            "       [  1.6,   1.2,   1.8, ...,   7.4,   7.2,   5. ],\n",
            "       [  1.6,   1.2,   0.8, ...,   9.4,   6.2,   8. ],\n",
            "       [  3.6,   1.2,   1.8, ...,   1.4,   6.2,   3. ]]), array([[ -8.6,  -5.2,  -6.6, ...,  -8. ,  -9. , -10.4],\n",
            "       [ 11.4,  10.8,  11.4, ...,   9. ,   2. ,   3.6],\n",
            "       [ -3.6,  -6.2,  -8.6, ...,  -6. ,  -1. ,  -5.4],\n",
            "       [ -8.6, -10.2,  -4.6, ...,  -3. ,   1. ,   1.6],\n",
            "       [  9.4,  10.8,   8.4, ...,   8. ,   7. ,  10.6]]), array([[  9. ,   9.4,   6.2, ..., -18.8, -16.8, -24. ],\n",
            "       [  6. ,   6.4,   5.2, ..., -14.8, -25.8, -29. ],\n",
            "       [ -5. ,  -6.6,  -4.8, ...,  22.2,  25.2,  21. ],\n",
            "       [ -5. ,  -5.6,  -1.8, ...,  18.2,  28.2,  23. ],\n",
            "       [ -5. ,  -3.6,  -4.8, ...,  -6.8, -10.8,   9. ]]), array([[ -9.8,  -1.4,  -3.4, ..., -20. , -11.4, -24.2],\n",
            "       [  4.2,  -1.4,   1.6, ...,   9. ,   6.6,   2.8],\n",
            "       [  3.2,   0.6,   0.6, ...,   3. ,   4.6,   5.8],\n",
            "       [  1.2,   2.6,   1.6, ...,   4. ,   3.6,   8.8],\n",
            "       [  1.2,  -0.4,  -0.4, ...,   4. ,  -3.4,   6.8]]), array([[  3.8,   5. ,   2.4, ...,  -3. , -12.4,   2.6],\n",
            "       [ -2.2, -12. ,  -8.6, ...,  30. ,  36.6,  29.6],\n",
            "       [ -1.2,   5. ,   2.4, ...,  -8. , -13.4, -17.4],\n",
            "       [  0.8,   3. ,   3.4, ...,  -8. ,  -9.4,  -8.4],\n",
            "       [ -1.2,  -1. ,   0.4, ..., -11. ,  -1.4,  -6.4]]), array([[-2.4,  1. , -1.4, ..., -1. ,  2. , -0.6],\n",
            "       [ 1.6, -2. , -1.4, ..., -6. ,  3. , -8.6],\n",
            "       [-1.4,  2. ,  0.6, ...,  6. , -4. ,  6.4],\n",
            "       [ 0.6,  2. , -0.4, ..., -3. , -2. , -3.6],\n",
            "       [ 1.6, -3. ,  2.6, ...,  4. ,  1. ,  6.4]]), array([[ 1.4,  4. ,  1.6, ...,  5.2,  8.4, -2. ],\n",
            "       [ 6.4,  4. ,  5.6, ..., -3.8, -0.6, -4. ],\n",
            "       [-9.6, -5. , -6.4, ...,  1.2,  1.4, 20. ],\n",
            "       [ 1.4, -1. ,  0.6, ..., -6.8, -9.6, -5. ],\n",
            "       [ 0.4, -2. , -1.4, ...,  4.2,  0.4, -9. ]]), array([[ 0.4, -0.2,  2. , ...,  3.4, -2.8,  6.2],\n",
            "       [-3.6, -4.2, -6. , ..., -0.6,  2.2, 10.2],\n",
            "       [ 2.4,  0.8,  4. , ..., -0.6,  5.2, -7.8],\n",
            "       [ 3.4,  2.8,  2. , ...,  0.4, -5.8, -6.8],\n",
            "       [-2.6,  0.8, -2. , ..., -2.6,  1.2, -1.8]]), array([[ -1.8,   2.8,  -0.8, ...,  -2.2, -38.6, -28.4],\n",
            "       [ -1.8,   0.8,   4.2, ..., -13.2, -11.6,   1.6],\n",
            "       [  1.2,  -1.2,  -0.8, ...,   8.8,   0.4, -33.4],\n",
            "       [  5.2,  -1.2,   1.2, ...,  53.8,  30.4, -13.4],\n",
            "       [ -2.8,  -1.2,  -3.8, ..., -47.2,  19.4,  73.6]]), array([[ 48.6,  47.8,  48.6, ...,   7.2,  27. ,  24. ],\n",
            "       [-33.4, -31.2, -34.4, ..., -38.8, -16. , -14. ],\n",
            "       [-34.4, -31.2, -34.4, ..., -32.8, -11. , -14. ],\n",
            "       [-27.4, -34.2, -31.4, ...,  63.2, -25. , -18. ],\n",
            "       [ 46.6,  48.8,  51.6, ...,   1.2,  25. ,  22. ]]), array([[  0. ,  -2. ,  -2.4, ..., -15.6,  -9.6,  -6.4],\n",
            "       [ 12. ,  14. ,  15.6, ...,  35.4,  21.4,  15.6],\n",
            "       [-14. , -14. , -12.4, ...,  -8.6,  -4.6,  -2.4],\n",
            "       [  3. ,   1. ,   1.6, ...,  -1.6,   4.4,  -2.4],\n",
            "       [ -1. ,   1. ,  -2.4, ...,  -9.6, -11.6,  -4.4]]), array([[ 3.6,  8.4,  5.6, ..., -4.2,  0.2, -7. ],\n",
            "       [ 0.6,  7.4,  4.6, ..., -3.2, -0.8, -3. ],\n",
            "       [-2.4, -6.6, -3.4, ...,  2.8,  2.2,  4. ],\n",
            "       [-1.4, -4.6, -1.4, ...,  3.8,  3.2,  7. ],\n",
            "       [-0.4, -4.6, -5.4, ...,  0.8, -4.8, -1. ]]), array([[  0.8,  -0.6,   2.8, ...,  -8.6, -12. ,  -7.4],\n",
            "       [  1.8,   0.4,  -1.2, ...,   4.4,   5. ,  -6.4],\n",
            "       [ -3.2,   2.4,  -2.2, ...,   5.4,   7. ,  10.6],\n",
            "       [ -0.2,  -0.6,  -0.2, ...,  -7.6, -12. ,  -5.4],\n",
            "       [  0.8,  -1.6,   0.8, ...,   6.4,  12. ,   8.6]]), array([[ 1.4, -5.8,  5.6, ...,  5.2,  8.4,  0.6],\n",
            "       [ 4.4,  5.2, -1.4, ..., -4.8, -7.6, -3.4],\n",
            "       [-1.6, -2.8, -1.4, ...,  3.2,  4.4, -0.4],\n",
            "       [ 3.4,  3.2,  1.6, ..., -2.8, -6.6, -2.4],\n",
            "       [-7.6,  0.2, -4.4, ..., -0.8,  1.4,  5.6]]), array([[  2. ,  -0.8,   0. , ...,  12. ,  18.4,  18.8],\n",
            "       [  5. ,   4.2,   5. , ..., -16. , -14.6, -20.2],\n",
            "       [  4. ,   6.2,   5. , ..., -13. , -13.6,  -8.2],\n",
            "       [ -9. ,  -8.8,  -9. , ...,   1. ,  -1.6,  -5.2],\n",
            "       [ -2. ,  -0.8,  -1. , ...,  16. ,  11.4,  14.8]]), array([[ -4.6, -11.4,  -5.4, ..., -20. , -33.8,   3.6],\n",
            "       [ -0.6,   0.6,   1.6, ..., -16. ,   5.2,  23.6],\n",
            "       [  3.4,   1.6,   1.6, ...,   0. , -13.8,   4.6],\n",
            "       [  0.4,   6.6,   2.6, ...,  18. ,  28.2,   0.6],\n",
            "       [  1.4,   2.6,  -0.4, ...,  18. ,  14.2, -32.4]]), array([[ -1.4,  -0.4,   3.2, ..., -19.8,  56.2,  88.2],\n",
            "       [  2.6,  -1.4,   0.2, ..., -78.8,  -9.8,  -0.8],\n",
            "       [ -1.4,  -2.4,  -3.8, ...,  51.2, -20.8,  -3.8],\n",
            "       [ -2.4,   2.6,  -3.8, ...,  19.2,  -2.8, -52.8],\n",
            "       [  2.6,   1.6,   4.2, ...,  28.2, -22.8, -30.8]]), array([[-0.2, -0.2, -0.8, ...,  0.8, -4.4, -3.6],\n",
            "       [-8.2, -1.2, -3.8, ...,  1.8,  9.6,  3.4],\n",
            "       [-1.2, -3.2, -4.8, ..., -3.2,  1.6,  6.4],\n",
            "       [ 3.8,  2.8,  3.2, ..., -1.2, -1.4, -5.6],\n",
            "       [ 5.8,  1.8,  6.2, ...,  1.8, -5.4, -0.6]]), array([[  0.8,  -2.2,  -0.4, ..., -47. ,  -1.4,   2. ],\n",
            "       [ -1.2,  -3.2,  -3.4, ..., -31. ,   6.6,   7. ],\n",
            "       [ -1.2,   1.8,  -0.4, ..., 135. ,   3.6, -14. ],\n",
            "       [  3.8,   3.8,   2.6, ..., -30. , -14.4,  -6. ],\n",
            "       [ -2.2,  -0.2,   1.6, ..., -27. ,   5.6,  11. ]]), array([[ 1.4, -0.8,  0. , ..., -9.6, -7.8,  1.4],\n",
            "       [ 2.4,  1.2,  2. , ...,  5.4,  2.2,  2.4],\n",
            "       [ 0.4,  0.2,  1. , ...,  4.4,  1.2, -7.6],\n",
            "       [-2.6,  0.2,  0. , ..., -0.6,  6.2, -2.6],\n",
            "       [-1.6, -0.8, -3. , ...,  0.4, -1.8,  6.4]]), array([[  4. ,  -1. ,  -0.8, ..., -10.4, -12.2, -13.4],\n",
            "       [  1. ,  -2. ,   1.2, ..., -19.4, -14.2,  -4.4],\n",
            "       [  0. ,   2. ,  -1.8, ...,   7.6,   4.8,  -2.4],\n",
            "       [ -3. ,  -1. ,   1.2, ...,   5.6,  11.8,  13.6],\n",
            "       [ -2. ,   2. ,   0.2, ...,  16.6,   9.8,   6.6]]), array([[10.4, -1.4,  1.6, ..., 11. , -2.6, -1. ],\n",
            "       [-2.6,  2.6,  1.6, ..., -7. , -2.6,  0. ],\n",
            "       [-3.6,  2.6, -2.4, ...,  1. ,  1.4,  1. ],\n",
            "       [-2.6, -0.4, -1.4, ..., -2. ,  2.4, -2. ],\n",
            "       [-1.6, -3.4,  0.6, ..., -3. ,  1.4,  2. ]]), array([[-42.2, -41.8, -47. , ...,  13.8,   9. , -14. ],\n",
            "       [-45.2, -43.8, -45. , ...,  -1.2,   4. ,   5. ],\n",
            "       [ 29.8,  27.2,  30. , ...,   3.8,   3. ,   8. ],\n",
            "       [ 27.8,  31.2,  30. , ...,   0.8,   1. ,   8. ],\n",
            "       [ 29.8,  27.2,  32. , ..., -17.2, -17. ,  -7. ]]), array([[ -1.4,  -4. ,  -1.8, ..., -16.2, -14.2, -13.6],\n",
            "       [  2.6,   3. ,   3.2, ...,  11.8,   9.8,   9.4],\n",
            "       [ -0.4,   1. ,   3.2, ...,   8.8,   7.8,   9.4],\n",
            "       [  2.6,   2. ,  -0.8, ...,  10.8,   9.8,  10.4],\n",
            "       [ -3.4,  -2. ,  -3.8, ..., -15.2, -13.2, -15.6]]), array([[  0.6,   1.6,   0.2, ..., -20.6, -24.4, -24.6],\n",
            "       [  0.6,   3.6,  -1.8, ..., -20.6, -20.4, -23.6],\n",
            "       [ -3.4,  -3.4,   0.2, ..., -14.6, -14.4, -16.6],\n",
            "       [  2.6,   0.6,   3.2, ...,  73.4,  75.6,  82.4],\n",
            "       [ -0.4,  -2.4,  -1.8, ..., -17.6, -16.4, -17.6]]), array([[-22.2, -26.2, -25.8, ...,  24.4,  47. ,   1. ],\n",
            "       [-24.2, -23.2, -22.8, ...,  26.4,  37. , -11. ],\n",
            "       [ 39.8,  40.8,  37.2, ..., -23.6, -43. , -34. ],\n",
            "       [ 36.8,  31.8,  37.2, ..., -54.6, -29. ,  -4. ],\n",
            "       [-30.2, -23.2, -25.8, ...,  27.4, -12. ,  48. ]]), array([[ 2. ,  0.2,  1.2, ..., -3.8,  1.2,  2. ],\n",
            "       [ 3. ,  0.2, -0.8, ..., -0.8,  1.2, -2. ],\n",
            "       [ 3. , -1.8,  1.2, ...,  5.2,  2.2,  3. ],\n",
            "       [-3. ,  1.2,  2.2, ...,  0.2, -0.8, -4. ],\n",
            "       [-5. ,  0.2, -3.8, ..., -0.8, -3.8,  1. ]]), array([[ 12. ,  10.8,  10.2, ..., -40.6,  -5.4,  -2.2],\n",
            "       [  8. ,   6.8,  10.2, ...,   2.4,   9.6,   3.8],\n",
            "       [-45. , -43.2, -34.8, ...,  74.4,  85.6,  55.8],\n",
            "       [ 19. ,  14.8,  13.2, ..., -26.6, -30.4, -49.2],\n",
            "       [  6. ,  10.8,   1.2, ...,  -9.6, -59.4,  -8.2]]), array([[-0.6,  2.4,  2.2, ..., -2.4, -4.4, -4. ],\n",
            "       [ 0.4,  1.4, -1.8, ...,  1.6,  4.6,  7. ],\n",
            "       [-0.6,  2.4, -2.8, ..., -1.4, -5.4, -7. ],\n",
            "       [ 0.4,  0.4,  1.2, ...,  0.6,  3.6,  2. ],\n",
            "       [ 0.4, -6.6,  1.2, ...,  1.6,  1.6,  2. ]]), array([[ -3.8,  -1.6,  -3. , ...,   8.4,   2.8, -22. ],\n",
            "       [ -5.8,   5.4,   8. , ..., -79.6, -56.2, -50. ],\n",
            "       [  5.2,  -1.6,  -4. , ..., -72.6, -58.2, -50. ],\n",
            "       [  2.2,   2.4,   3. , ...,  76.4,  49.8,  52. ],\n",
            "       [  2.2,  -4.6,  -4. , ...,  67.4,  61.8,  70. ]]), array([[ -1. ,   1.4,  -1.6, ..., -10.8, -10. ,  -6. ],\n",
            "       [  1. ,  -0.6,   2.4, ..., -11.8, -18. , -17. ],\n",
            "       [ -1. ,  -2.6,  -3.6, ..., -19.8, -26. , -13. ],\n",
            "       [  1. ,   3.4,  -1.6, ...,  63.2,  44. ,  10. ],\n",
            "       [  0. ,  -1.6,   4.4, ..., -20.8,  10. ,  26. ]]), array([[-11.6, -17.4, -12.6, ..., -19.6, -23. ,  -8. ],\n",
            "       [ -5.6, -16.4, -16.6, ..., -18.6, -14. ,  -9. ],\n",
            "       [-16.6, -14.4, -11.6, ..., -16.6, -12. , -14. ],\n",
            "       [-18.6, -10.4, -15.6, ...,  -3.6,  10. , -17. ],\n",
            "       [ 52.4,  58.6,  56.4, ...,  58.4,  39. ,  48. ]]), array([[ -5.8,  -2.6,  -2.6, ...,  -3.2,  -9. ,   8. ],\n",
            "       [  0.2,   2.4,   4.4, ...,  -3.2,   4. ,   0. ],\n",
            "       [  4.2,   3.4,   0.4, ...,  -1.2,   2. ,   3. ],\n",
            "       [  3.2,   0.4,   3.4, ...,   3.8,  -2. ,   6. ],\n",
            "       [ -1.8,  -3.6,  -5.6, ...,   3.8,   5. , -17. ]]), array([[ -9.6,  -6.4, -10.2, ...,   0.2,  -5.8,  -4.4],\n",
            "       [-10.6,  -9.4,  -7.2, ...,  -6.8,  -6.8,   2.6],\n",
            "       [ 12.4,  10.6,   6.8, ...,  28.2,  23.2,  11.6],\n",
            "       [  3.4,   1.6,   3.8, ...,   1.2,  -2.8,  -1.4],\n",
            "       [  4.4,   3.6,   6.8, ..., -22.8,  -7.8,  -8.4]]), array([[  1. ,   7.4,   2.2, ...,  46.2,  38. ,  40. ],\n",
            "       [  4. ,  -0.6,   1.2, ..., -14.8,  -9. ,  -9. ],\n",
            "       [ -3. ,  -2.6,   0.2, ...,  -7.8, -11. ,  -7. ],\n",
            "       [ -1. ,  -4.6,  -1.8, ..., -11.8,  -7. ,  -9. ],\n",
            "       [ -1. ,   0.4,  -1.8, ..., -11.8, -11. , -15. ]])]\n",
            "S=  (10304, 10304)\n",
            "[[ 28496.8  27128.2  27372.4 ...  -3977.2  -3511.6    539. ]\n",
            " [ 27128.2  28448.8  27518.6 ...  -2697.2  -2349.2   1781.6]\n",
            " [ 27372.4  27518.6  28698.4 ...  -3472.2   -923.2   3416.2]\n",
            " ...\n",
            " [ -3977.2  -2697.2  -3472.2 ... 140034.   83425.8  64222.2]\n",
            " [ -3511.6  -2349.2   -923.2 ...  83425.8  99585.6  82754.4]\n",
            " [   539.    1781.6   3416.2 ...  64222.2  82754.4 104148.8]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XBmGOU8kUhdL",
        "outputId": "2e0ca193-3ce6-4c6d-aee1-2ead57234c25"
      },
      "source": [
        "inv=np.linalg.inv(ListOfScatterMatrcies)\n",
        "math_symm = (np.triu_indices(len(inv), 1))\n",
        "inv[math_symm]=np.tril(inv, -1).T[math_symm]\n",
        "\n",
        "print(inv)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 2.41927224e+10 -1.08670945e+10  2.54571078e+10 ...  3.64317151e+09\n",
            "  -4.19315811e+09 -1.87594061e+09]\n",
            " [-1.08670945e+10  1.95704296e+10 -2.15524699e+10 ... -6.67123128e+08\n",
            "   4.87576934e+08 -8.23215873e+08]\n",
            " [ 2.54571078e+10 -2.15524699e+10  1.30523468e+10 ...  1.85670327e+09\n",
            "  -2.83395492e+09 -1.47503002e+09]\n",
            " ...\n",
            " [ 3.64317151e+09 -6.67123128e+08  1.85670327e+09 ... -2.08734659e+09\n",
            "   2.57987819e+09  6.41637579e+08]\n",
            " [-4.19315811e+09  4.87576934e+08 -2.83395492e+09 ...  2.57987819e+09\n",
            "  -6.18200646e+09  3.90041512e+08]\n",
            " [-1.87594061e+09 -8.23215873e+08 -1.47503002e+09 ...  6.41637579e+08\n",
            "   3.90041512e+08 -5.22071836e+08]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YqTNB3_zVEAw",
        "outputId": "5bc680f6-7689-4d77-fcfa-c0b135fe3193"
      },
      "source": [
        "s_1_b=np.dot(inv,Sb)\n",
        "\n",
        "\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[-3.92517924e+15 -3.97159571e+15 -3.84405827e+15 ... -6.67481770e+14\n",
            "  -2.25360090e+15 -9.76205022e+14]\n",
            " [-2.34567651e+15 -2.38995980e+15 -2.15789869e+15 ...  2.05696221e+15\n",
            "   9.53844506e+14  1.04112749e+15]\n",
            " [-6.24457868e+15 -6.27436293e+15 -6.05200786e+15 ...  4.52820028e+14\n",
            "  -1.10054112e+15 -2.49663985e+14]\n",
            " ...\n",
            " [ 4.27318739e+15  4.31769286e+15  4.38372799e+15 ...  9.97069720e+15\n",
            "   7.47922023e+15  6.61051980e+15]\n",
            " [-8.11195835e+15 -8.27061400e+15 -8.19195501e+15 ... -1.33107902e+16\n",
            "  -1.02617986e+16 -9.08604286e+15]\n",
            " [-2.74238517e+15 -2.82355977e+15 -2.80150292e+15 ... -6.87271818e+15\n",
            "  -6.41174803e+15 -5.87995514e+15]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M4lRlFGObjKz",
        "outputId": "981bf3eb-59b5-4139-8a83-df5df5115074"
      },
      "source": [
        "math_symm = (np.triu_indices(len(s_1_b), 1))\n",
        "s_1_b[math_symm]=np.tril(s_1_b, -1).T[math_symm]\n",
        "print(s_1_b)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[-3.92517924e+15 -2.34567651e+15 -6.24457868e+15 ...  4.27318739e+15\n",
            "  -8.11195835e+15 -2.74238517e+15]\n",
            " [-2.34567651e+15 -2.38995980e+15 -6.27436293e+15 ...  4.31769286e+15\n",
            "  -8.27061400e+15 -2.82355977e+15]\n",
            " [-6.24457868e+15 -6.27436293e+15 -6.05200786e+15 ...  4.38372799e+15\n",
            "  -8.19195501e+15 -2.80150292e+15]\n",
            " ...\n",
            " [ 4.27318739e+15  4.31769286e+15  4.38372799e+15 ...  9.97069720e+15\n",
            "  -1.33107902e+16 -6.87271818e+15]\n",
            " [-8.11195835e+15 -8.27061400e+15 -8.19195501e+15 ... -1.33107902e+16\n",
            "  -1.02617986e+16 -6.41174803e+15]\n",
            " [-2.74238517e+15 -2.82355977e+15 -2.80150292e+15 ... -6.87271818e+15\n",
            "  -6.41174803e+15 -5.87995514e+15]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bnQBnqFHWsl7",
        "outputId": "e84fc236-1559-4f77-9995-163dbddd1c15"
      },
      "source": [
        "EigenValues,EigenVector=np.linalg.eigh(s_1_b)\n",
        "print(EigenValues.shape)\n",
        "print(EigenValues)\n",
        "print(EigenVector.shape)\n",
        "print(EigenVector)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10304,)\n",
            "[-2.77146596e+19 -1.90595178e+19 -1.57557444e+19 ...  1.62094715e+19\n",
            "  1.92151487e+19  2.81495349e+19]\n",
            "(10304, 10304)\n",
            "[[-0.01719123  0.00909356 -0.02676178 ...  0.02664646 -0.00898708\n",
            "   0.01731865]\n",
            " [-0.01698555  0.00913003 -0.02685456 ...  0.02673725 -0.00905747\n",
            "   0.017107  ]\n",
            " [-0.01720716  0.0091637  -0.02634558 ...  0.02623938 -0.0090471\n",
            "   0.01733775]\n",
            " ...\n",
            " [ 0.01519214  0.02567703 -0.00283949 ... -0.00166007  0.02610118\n",
            "   0.01440244]\n",
            " [-0.01791855 -0.02957834 -0.00174358 ... -0.00283793 -0.02984239\n",
            "  -0.01700352]\n",
            " [-0.00459661 -0.00821291 -0.00191172 ... -0.00178508 -0.00816821\n",
            "  -0.00445732]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iZep7vVyEZZF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b69a474-837f-4ff8-a04c-a14a67199dd2"
      },
      "source": [
        "idx = np.argsort(EigenValues)[::-1]\n",
        "Sorted_eigenValues= EigenValues[idx]\n",
        "Sorted_eigenvectors= EigenVector[:,idx]\n",
        "\n",
        "Reduced_Dimensions=Sorted_eigenvectors[0:39]\n",
        "\n",
        "\n",
        "LDAProjectionMatrix=Reduced_Dimensions.T\n",
        "print(LDAProjectionMatrix)\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 0.01731865  0.017107    0.01733775 ... -0.00826129 -0.00772953\n",
            "  -0.00751452]\n",
            " [-0.00898708 -0.00905747 -0.0090471  ... -0.00933998 -0.00860887\n",
            "  -0.00771004]\n",
            " [ 0.02664646  0.02673725  0.02623938 ...  0.01610841  0.01477417\n",
            "   0.0159703 ]\n",
            " ...\n",
            " [-0.02676178 -0.02685456 -0.02634558 ... -0.0170666  -0.01480786\n",
            "  -0.01569157]\n",
            " [ 0.00909356  0.00913003  0.0091637  ...  0.00895887  0.00800696\n",
            "   0.00695244]\n",
            " [-0.01719123 -0.01698555 -0.01720716 ...  0.00795673  0.00768434\n",
            "   0.00755853]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9QY-2Qw0dBFI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f138710f-fd9b-4c6a-e46d-bb612bdbab42"
      },
      "source": [
        "LDAProjectedTraining=np.dot(Training,LDAProjectionMatrix)\n",
        "print(LDAProjectedTraining)\n",
        "print(LDAProjectedTraining.shape)\n",
        "LDAProjectedTesting=np.dot(Testing,LDAProjectionMatrix)\n",
        "print(LDAProjectedTesting)\n",
        "print(LDAProjectedTesting.shape)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[  11.93511642   30.87641889  166.15323611 ...   58.79896321\n",
            "    -8.89304079  123.48869242]\n",
            " [ -63.26706298  -57.06554497   70.04464645 ...  184.76254506\n",
            "    34.98155037   33.77875472]\n",
            " [ -19.72374092  -59.49694256   50.15809164 ...  183.34983256\n",
            "    18.2941753   108.89997014]\n",
            " ...\n",
            " [  70.85117213 -100.47747556  130.17942181 ...   64.7868816\n",
            "    63.57019454  -45.55198244]\n",
            " [  59.21787855 -107.29107506  129.08204462 ...   92.03545402\n",
            "     3.69750307  -14.68856274]\n",
            " [  44.541023    -66.92704733  109.1434135  ...   40.22626668\n",
            "    47.67960014   11.65282923]]\n",
            "(200, 39)\n",
            "[[ 32.05624323 -80.71355963  90.91108358 ... 101.84789291  57.87151351\n",
            "   62.02995027]\n",
            " [ -3.25433331 -91.82892916  74.04238544 ...  54.16240563  58.02963133\n",
            "  100.16393968]\n",
            " [-58.32133919 -35.46455606 109.25571518 ... 124.81067698  21.70591883\n",
            "   63.97910939]\n",
            " ...\n",
            " [ 26.92925601 -80.95000773 138.92234214 ...  96.24601983  45.0825278\n",
            "  -22.03996982]\n",
            " [-50.68589795 -15.26458804 143.13489874 ...  90.32259237  19.57888858\n",
            "   43.84561303]\n",
            " [-24.34401539   7.47491515  96.39312562 ... 140.0859981  -36.44676456\n",
            "   67.61380113]]\n",
            "(200, 39)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RxW3PQKLeRk3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "efb64d55-4bf0-4086-ea3f-4d6780baddf5"
      },
      "source": [
        "LDAPredictedLabels=Label_prediction(1,LDAProjectedTraining,LDAProjectedTesting)\n",
        "print(LDAPredictedLabels)\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[16 32 13 19  1  2  2  2  2  2  3  3 37  3  3  4  4  4  4  4  5  5  5  5\n",
            "  5  6  6  6  6  6  7  7  7  7  7  8  8  8  8  8  9  9  9  9  9 10 10 10\n",
            " 10 30 11 11 11 11 11 12 37 12 12 12 13 13 13 13 13 14 14 14 14 14 15 15\n",
            " 15 15 15 24 16 16 16  2 17 17 17 17 17 18 18 18 18 18 19 19 19 19 15 20\n",
            " 20  4  4 20 21 21 21  9 21 22 22 22 22 22 23  9 30 23 23 24 24  8 24 24\n",
            " 25 25 25 25 25 26 26 26 37 26 27 27 27 27 27 28 28 28 28 28 29 29 29 29\n",
            " 39 30 30 30 30 30 31 31 31 31 31 32  5 32  2 32 39 39 33 33 33 34 34 34\n",
            " 34 34 40  5  5 35 32 36 36  3 36 36 37 28 37 37 37 38 38 38 38 23 39 39\n",
            " 39 39 39 40 40 40  5  5]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7lLB1Mj9e8t7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c74b0195-7dff-4235-d494-1357f831b2df"
      },
      "source": [
        "LDA_Accuracy1 = accuracy_score(Original_Testing_Labels, LDAPredictedLabels)\n",
        "print(\"Accuracy1 = \",LDA_Accuracy1*100, \"%\")"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy1 =  84.5 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UL7jodsvpVcK"
      },
      "source": [
        "### **Classfier tunning**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tEDNSTvefpx-",
        "outputId": "3006caaf-260d-4f7d-d17b-5463fc536b4a"
      },
      "source": [
        "AccuracyLDA=[]\n",
        "\n",
        "AccuracyLDA.append([1,LDA_Accuracy1])\n",
        "\n",
        "LDAPredictedLabels3=Label_prediction(3,LDAProjectedTraining,LDAProjectedTesting)\n",
        "LDA_Accuracy3 = accuracy_score(Original_Testing_Labels, LDAPredictedLabels3)\n",
        "AccuracyLDA.append([3,LDA_Accuracy3])\n",
        "print(LDAPredictedLabels3)\n",
        "\n",
        "print(\"\\n *********************************** \\n\")\n",
        "\n",
        "LDAPredictedLabels5=Label_prediction(5,LDAProjectedTraining,LDAProjectedTesting)\n",
        "LDA_Accuracy5 = accuracy_score(Original_Testing_Labels, LDAPredictedLabels5)\n",
        "AccuracyLDA.append([5,LDA_Accuracy5])\n",
        "print(LDAPredictedLabels5)\n",
        "\n",
        "print(\"\\n *********************************** \\n\")\n",
        "\n",
        "LDAPredictedLabels7=Label_prediction(7,LDAProjectedTraining,LDAProjectedTesting)\n",
        "LDA_Accuracy7 = accuracy_score(Original_Testing_Labels, LDAPredictedLabels7)\n",
        "AccuracyLDA.append([7,LDA_Accuracy7])\n",
        "print(LDAPredictedLabels7)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 1 24  1  1  1 36  2 19  2 15  3  3  5  3  3  4  4  4 23  4  5  5  5 40\n",
            "  5  6  6  6  6  6  7  7  7  7  7  8  8  8  8  8  9  9  9  9  4 10 10 10\n",
            " 10 10 11 11 11 11 11 12 12 12 12 12 40  5 13 13  3 14 14 14 14 14 15 15\n",
            "  9 25 30 11 16  7 16  1  7 17 17 17 17 18  5 18 18 18 19 19 19 19 19  4\n",
            " 29 20 20 20 21 21 21 21 21 22 22 22 22 22 23 23 23 23 23 24 24 16 24 24\n",
            " 25 25  5 25 25 26  5 26 26  4 27 27 27 27 27 28 28 22 22  7 29 29 29 29\n",
            "  4 30  9 30 30 30 31 31 31 33  9  7 32 32  1 32 39  9 39 21 21 34 34 34\n",
            " 34 34 35 15 25 15 35  7 19  7 36  7 26  5 37 15  5 38  4  9 23 38 39 39\n",
            " 39 39 39  5  4  5  5  5]\n",
            "\n",
            " *********************************** \n",
            "\n",
            "[ 1  1  1  1  1  7  2 19  2 15  3  3  5  3  3  4  4  4 23  4  5  5  5  5\n",
            "  5  6  6  6  6  6  7  7  7  7  7  8  8  8  8  8  9  9  9  9  4 10 10 10\n",
            " 10 10 11 22 11 11 11 12  3 12 12 12 40 18 13 13  3 14 14 14 14 14 15 15\n",
            " 25 25 30 17 16  7 16 16  7 17  7 17 17 18  5 18 18 18 19 19  7  7  7 23\n",
            " 29 20 20 20 21 21 21 21 21 22 22 22 22 22 23 23 23 23 23 24 24 16 24 24\n",
            " 25 25  5 25 25 26 18 26 26  3 27 27 27 27 27 26 28 37 28 37 29 29 29 29\n",
            "  9 30  9 30 30 30 31 31 31 33 30  7 19 32 32 32 39 25 39 21 21 34 34 34\n",
            " 34 34 35 35  5 25 35  7 19  7  2  7  5  5 37  5  5  9  4 38 23 38 39 39\n",
            " 39 39 39  5  3  5  5  5]\n",
            "\n",
            " *********************************** \n",
            "\n",
            "[ 1 32  1  1  1  2  2  7  2 15  3  3  5 29  3  4  4  4 23  4  5 40  5 40\n",
            "  5  6  6  6  6  6  7  7  7  7  7  8  8  8  8  8  9  9  9  9  4 10 10 10\n",
            " 10  8 11 22 11 11 11 12  3 12 12 12 40 18 13 40 40 14 14 14 14 14 15 15\n",
            " 25 25 30 17 16  7 16 16  7 17  7 17 17 18 18 18 18 18 19 19  7  7  7 23\n",
            " 29 17 20 20 21 21 21 21 21 22 22 22 22 22 23 23 23 23 23 24 16 24 24 24\n",
            " 25 25  5 25 25 26  5 26 28  3 27 27 27 27 27 28 28 37 37  7 29 29 29 29\n",
            "  9 30  9 30 30 30  9 34 31 33 30 32 19 32 32 32 39  9 39 21 21 34 34 34\n",
            " 34 34 35 35  5 25 35  7  7  7  2  7  5  5 37  5  5  9  4 23 23 38 39 39\n",
            " 39 39 39  5 23  5  5  5]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TUAdoykFcZKQ",
        "outputId": "cc818661-4409-44a0-bfde-571782ce2c4a"
      },
      "source": [
        "\n",
        "print (tabulate(AccuracyLDA, headers=[\"K\", \"Accuracy\"]))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  K    Accuracy\n",
            "---  ----------\n",
            "  1       0.805\n",
            "  3       0.71\n",
            "  5       0.695\n",
            "  7       0.655\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CLn3VYKLjDCn",
        "outputId": "d0a47d0f-ac26-4e53-bf71-f7814096c826"
      },
      "source": [
        "PCAPredictedLabels08=[]\n",
        "PCAPredictedLabels085=[]\n",
        "PCAPredictedLabels09=[]\n",
        "PCAPredictedLabels095=[]\n",
        "PCA_Accuracy08=[]\n",
        "PCA_Accuracy085=[]\n",
        "PCA_Accuracy09=[]\n",
        "PCA_Accuracy095=[]\n",
        "K=[1,3,5,7]\n",
        "for i in range(0,4):\n",
        "  PCAPredictedLabels08.append(Label_prediction(K[i],projected_training08,projected_testing08))\n",
        "  PCAPredictedLabels085.append(Label_prediction(K[i],projected_training085,projected_testing085))\n",
        "  PCAPredictedLabels09.append(Label_prediction(K[i],projected_training09,projected_testing09))\n",
        "  PCAPredictedLabels095.append(Label_prediction(K[i],projected_training095,projected_testing095))\n",
        "for i in range(0,4):\n",
        "  PCA_Accuracy08.append([K[i],accuracy_score(Original_Testing_Labels, PCAPredictedLabels08[i])])\n",
        "  PCA_Accuracy085.append([K[i],accuracy_score(Original_Testing_Labels, PCAPredictedLabels085[i])])\n",
        "  PCA_Accuracy09.append([K[i],accuracy_score(Original_Testing_Labels, PCAPredictedLabels09[i])])\n",
        "  PCA_Accuracy095.append([K[i],accuracy_score(Original_Testing_Labels, PCAPredictedLabels095[i])])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print(\"Classifying accuracy with respect to k for PCA (Alpha=0.8) \\n\")\n",
        "print (tabulate(PCA_Accuracy08, headers=[\"K\", \"Accuracy\"]))\n",
        "\n",
        "print(\"\\n Classifying accuracy with respect to k for PCA (Alpha=0.85) \\n\")\n",
        "print (tabulate(PCA_Accuracy085, headers=[\"K\", \"Accuracy\"]))\n",
        "\n",
        "print(\"\\n Classifying accuracy with respect to k for PCA (Alpha=0.9) \\n\")\n",
        "print (tabulate(PCA_Accuracy09, headers=[\"K\", \"Accuracy\"]))\n",
        "\n",
        "print(\"\\n Classifying accuracy with respect to k for PCA (Alpha=0.95) \\n\")\n",
        "print (tabulate(PCA_Accuracy095, headers=[\"K\", \"Accuracy\"]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Classifying accuracy with respect to k for PCA (Alpha=0.8) \n",
            "\n",
            "  K    Accuracy\n",
            "---  ----------\n",
            "  1       0.93\n",
            "  3       0.855\n",
            "  5       0.805\n",
            "  7       0.78\n",
            "\n",
            " Classifying accuracy with respect to k for PCA (Alpha=0.85) \n",
            "\n",
            "  K    Accuracy\n",
            "---  ----------\n",
            "  1       0.94\n",
            "  3       0.855\n",
            "  5       0.83\n",
            "  7       0.775\n",
            "\n",
            " Classifying accuracy with respect to k for PCA (Alpha=0.9) \n",
            "\n",
            "  K    Accuracy\n",
            "---  ----------\n",
            "  1       0.945\n",
            "  3       0.85\n",
            "  5       0.815\n",
            "  7       0.755\n",
            "\n",
            " Classifying accuracy with respect to k for PCA (Alpha=0.95) \n",
            "\n",
            "  K    Accuracy\n",
            "---  ----------\n",
            "  1       0.935\n",
            "  3       0.845\n",
            "  5       0.815\n",
            "  7       0.74\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "apxBKyKjPYgr"
      },
      "source": [
        "### **Non-Faces/Faces**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QLzv6nEZPe0l",
        "outputId": "89df23ec-95d1-4a9e-ee59-fcfa5c0b33fe"
      },
      "source": [
        "img = Image.open('/content/dog (3).pgm')     \n",
        "data = np.array(img)     \n",
        "print(data.shape)     \n",
        "x = data.flatten()         \n",
        "print(x.shape)\n",
        "  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(92, 112)\n",
            "(10304,)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}